{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMjdCwHUb1Jidz3XXBjqozF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Asaad972/CollabFirstNoteBook/blob/main/HW02_Cloud.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ZcwcS_-VsXcf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cab0ac9d-6f06-4ba0-a325-8a8d5e68a3f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Dependencies ready\n"
          ]
        }
      ],
      "source": [
        "# CELL 1: Minimal package installation (only if missing)\n",
        "import importlib.util, sys, subprocess\n",
        "\n",
        "def ensure(pkg, import_name=None):\n",
        "    name = import_name or pkg\n",
        "    if importlib.util.find_spec(name) is None:\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg])\n",
        "\n",
        "# Usually already installed in Colab, but keep safe:\n",
        "ensure(\"pandas\", \"pandas\")\n",
        "\n",
        "# Required for your homework plan:\n",
        "ensure(\"nltk\", \"nltk\")\n",
        "ensure(\"sentence-transformers\", \"sentence_transformers\")\n",
        "ensure(\"faiss-cpu\", \"faiss\")\n",
        "\n",
        "print(\"âœ… Dependencies ready\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 2: Imports + NLTK resources (run once per runtime)\n",
        "\n",
        "import re\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "\n",
        "# NLTK downloads (required for stopwords/tokenizer/lemmatizer)\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"omw-1.4\")\n",
        "nltk.download(\"punkt_tab\")\n",
        "\n",
        "print(\"âœ… Imports ready + NLTK resources downloaded\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2wDldDHHb8tY",
        "outputId": "048861d6-1283-4ebc-c3a0-8e0b60b2f29a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:torchao.kernel.intmm:Warning: Detected no triton, on systems without Triton certain kernels will not work\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Imports ready + NLTK resources downloaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install firebase-admin"
      ],
      "metadata": {
        "id": "ZC9ylYlDelUY"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 3: Store Classes (Vector Store + Inverted Index)\n",
        "# =====================================================\n",
        "\"\"\"\n",
        "ðŸ—„ï¸ CELL 3: STORE CLASSES\n",
        "- SimpleVectorStore: stores embeddings + documents + metadatas + ids (like Tirgul 7)\n",
        "- InvertedIndexStore: stores required index schema term -> DocIDs (homework requirement)\n",
        "\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "from collections import defaultdict\n",
        "\n",
        "# ---------- Vector Store (similar to Tirgul 7) ----------\n",
        "class SimpleVectorStore:\n",
        "    \"\"\"Simple in-memory vector store (fallback)\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.documents = []\n",
        "        self.embeddings = []   # list of numpy arrays\n",
        "        self.metadatas = []\n",
        "        self.ids = []\n",
        "        print(\"ðŸ“¦ SimpleVectorStore initialized\")\n",
        "\n",
        "    def add(self, embeddings, documents, metadatas, ids):\n",
        "        # Ensure numpy arrays\n",
        "        embeddings = [np.asarray(e, dtype=np.float32) for e in embeddings]\n",
        "        self.embeddings.extend(embeddings)\n",
        "        self.documents.extend(documents)\n",
        "        self.metadatas.extend(metadatas)\n",
        "        self.ids.extend(ids)\n",
        "        print(f\"âœ… Added {len(documents)} documents to simple vector store\")\n",
        "\n",
        "    def query(self, query_embeddings, n_results=5):\n",
        "        if not self.embeddings:\n",
        "            return {'ids': [[]], 'documents': [[]], 'metadatas': [[]], 'distances': [[]]}\n",
        "\n",
        "        q = np.asarray(query_embeddings[0], dtype=np.float32)\n",
        "\n",
        "        E = np.vstack(self.embeddings)  # shape: (N, d)\n",
        "\n",
        "        # cosine similarity without sklearn\n",
        "        q_norm = np.linalg.norm(q) + 1e-12\n",
        "        E_norm = np.linalg.norm(E, axis=1) + 1e-12\n",
        "        sims = (E @ q) / (E_norm * q_norm)\n",
        "\n",
        "        top_idx = np.argsort(sims)[::-1][:n_results]\n",
        "\n",
        "        return {\n",
        "            'ids': [[self.ids[i] for i in top_idx]],\n",
        "            'documents': [[self.documents[i] for i in top_idx]],\n",
        "            'metadatas': [[self.metadatas[i] for i in top_idx]],\n",
        "            'distances': [[float(1 - sims[i]) for i in top_idx]]  # distance-like\n",
        "        }\n",
        "\n",
        "    def count(self):\n",
        "        return len(self.documents)\n",
        "\n",
        "\n",
        "# ---------- Inverted Index (required by homework) ----------\n",
        "class InvertedIndexStore:\n",
        "    \"\"\"Required structure: term -> DocIDs\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.term_to_docids = defaultdict(set)\n",
        "        print(\"ðŸ“¦ InvertedIndexStore initialized\")\n",
        "\n",
        "    def add_occurrence(self, term: str, doc_id: str):\n",
        "        self.term_to_docids[term].add(doc_id)\n",
        "\n",
        "    def get_docids(self, term: str):\n",
        "        return sorted(self.term_to_docids.get(term, set()))\n",
        "\n",
        "    def count_terms(self) -> int:\n",
        "        return len(self.term_to_docids)\n",
        "\n",
        "    def to_required_format(self):\n",
        "        # [{\"term\": ..., \"DocIDs\": [...]}, ...]\n",
        "        return [{\"term\": t, \"DocIDs\": sorted(list(docids))}\n",
        "                for t, docids in sorted(self.term_to_docids.items())]\n",
        "\n",
        "\n",
        "print(\"âœ… Store classes defined!\")\n",
        "print(\"ðŸ“‹ Next: Cell 4 (core logic: preprocess + build index + embeddings)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H6h6ichmcgHy",
        "outputId": "eca72ab3-e153-496e-d3a0-10edcb66b56e"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Store classes defined!\n",
            "ðŸ“‹ Next: Cell 4 (core logic: preprocess + build index + embeddings)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 4: Core setup (custom stopwords + stemming + embedding model + FAISS)\n",
        "\n",
        "# --- Custom stopwords (you define them) ---\n",
        "# We remove these words because they are very frequent function words (articles, prepositions, pronouns).\n",
        "# They usually do not add topic meaning, but they increase index size and add noise to retrieval.\n",
        "CUSTOM_STOPWORDS = {\n",
        "    \"the\",\"a\",\"an\",\"and\",\"or\",\"but\",\n",
        "    \"to\",\"of\",\"in\",\"on\",\"at\",\"for\",\"from\",\"by\",\"with\",\"as\",\n",
        "    \"is\",\"are\",\"was\",\"were\",\"be\",\"been\",\"being\",\n",
        "    \"this\",\"that\",\"these\",\"those\",\n",
        "    \"it\",\"its\",\"they\",\"them\",\"their\",\"we\",\"our\",\"you\",\"your\",\n",
        "    \"i\",\"me\",\"my\",\"he\",\"him\",\"his\",\"she\",\"her\",\n",
        "    \"not\",\"no\",\"do\",\"does\",\"did\",\"doing\"\n",
        "}\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def preprocess_text(text: str):\n",
        "    \"\"\"\n",
        "    Returns list of terms for indexing:\n",
        "    - lowercase\n",
        "    - tokenize\n",
        "    - keep alphabetic tokens only\n",
        "    - remove custom stopwords\n",
        "    - apply stemming\n",
        "    \"\"\"\n",
        "    text = text.lower()\n",
        "    tokens = word_tokenize(text)\n",
        "    terms = []\n",
        "    for tok in tokens:\n",
        "        if tok.isalpha() and tok not in CUSTOM_STOPWORDS:\n",
        "            terms.append(stemmer.stem(tok))\n",
        "    return terms\n",
        "\n",
        "# --- Embedding model (for semantic retrieval) ---\n",
        "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# --- FAISS index (stores embeddings for doc-level retrieval) ---\n",
        "faiss_index = None\n",
        "vector_dim = None\n",
        "\n",
        "# Parallel stores (FAISS row -> doc data)\n",
        "vector_doc_ids = []   # doc_id\n",
        "vector_texts = []     # full doc text\n",
        "\n",
        "print(\"âœ… Core setup ready (custom stopwords + stemming + embeddings + FAISS)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ly5DF07crLF",
        "outputId": "cb1d7f66-40e2-44f5-babc-d09e8578cfa9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Core setup ready (custom stopwords + stemming + embeddings + FAISS)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 5: Sample Papers (metadata + file names)\n",
        "\n",
        "sample_papers = [\n",
        "    {\n",
        "        \"title\": \"AI-IoT Based Smart Agriculture Pivot for Plant Diseases Detection and Treatment\",\n",
        "        \"authors\": \"AS Ibrahim et al.\",\n",
        "        \"journal\": \"Scientific Reports (Nature)\",\n",
        "        \"year\": 2025,\n",
        "        \"doi\": \"10.1038/s41598-025-98454-6\",\n",
        "        \"abstract\": \"Proposes an AI-IoT smart agriculture pivot architecture for detecting and treating plant diseases, including a hardware pilot and mobile-app support.\",\n",
        "        \"file\": \"s41598-025-98454-6.pdf\"\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"Infectious Plant Diseases: Etiology, Current Status, Problems and Prospects in Plant Protection\",\n",
        "        \"authors\": \"PA Nazarov et al.\",\n",
        "        \"journal\": \"Acta Naturae\",\n",
        "        \"year\": 2020,\n",
        "        \"doi\": None,\n",
        "        \"abstract\": \"Review of infectious plant diseases caused by viruses, bacteria, and fungi; current status and prospects for plant protection.\",\n",
        "        \"file\": \"actanaturae_11026.pdf\"\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"Recent Approaches towards Control of Fungal Diseases in Plants: An Updated Review\",\n",
        "        \"authors\": \"NA El-Baky, AAAF Amara\",\n",
        "        \"journal\": \"Journal of Fungi (MDPI)\",\n",
        "        \"year\": 2021,\n",
        "        \"doi\": \"10.3390/jof7110900\",\n",
        "        \"abstract\": \"Reviews strategies to control plant fungal diseases including biocontrol and other approaches.\",\n",
        "        \"file\": \"jof-07-00900.pdf\"\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"The Potential Risk of Plant-Virus Disease Initiation by Infected Tomatoes\",\n",
        "        \"authors\": \"C Klap et al.\",\n",
        "        \"journal\": \"Plants (MDPI)\",\n",
        "        \"year\": 2020,\n",
        "        \"doi\": \"10.3390/plants9050623\",\n",
        "        \"abstract\": \"Study on how infected tomatoes can contribute to plant-virus disease spread and transmission risk.\",\n",
        "        \"file\": \"plants-09-00623.pdf\"\n",
        "    },\n",
        "    {\n",
        "        \"title\": \"Current status and future perspectives of the diagnostic of plant bacterial pathogens\",\n",
        "        \"authors\": \"X Wang et al.\",\n",
        "        \"journal\": \"Frontiers in Plant Science\",\n",
        "        \"year\": 2025,\n",
        "        \"doi\": None,\n",
        "        \"abstract\": \"Review of plant bacterial pathogen diagnostics; shift from culture-based to culture-free detection; limitations in real plant extracts and recent progress.\",\n",
        "        \"file\": \"fpls-2025-bacterial-pathogen-diagnostics.pdf\"\n",
        "    }\n",
        "]\n",
        "\n",
        "print(f\"ðŸ“š sample_papers ready: {len(sample_papers)} papers\")\n",
        "for i, p in enumerate(sample_papers, 1):\n",
        "    print(f\"{i}. {p['title']}  -->  {p['file']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F5Swqy3GdK37",
        "outputId": "d96f285c-37a7-4e23-a840-410504d8bcfe"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“š sample_papers ready: 5 papers\n",
            "1. AI-IoT Based Smart Agriculture Pivot for Plant Diseases Detection and Treatment  -->  s41598-025-98454-6.pdf\n",
            "2. Infectious Plant Diseases: Etiology, Current Status, Problems and Prospects in Plant Protection  -->  actanaturae_11026.pdf\n",
            "3. Recent Approaches towards Control of Fungal Diseases in Plants: An Updated Review  -->  jof-07-00900.pdf\n",
            "4. The Potential Risk of Plant-Virus Disease Initiation by Infected Tomatoes  -->  plants-09-00623.pdf\n",
            "5. Current status and future perspectives of the diagnostic of plant bacterial pathogens  -->  fpls-2025-bacterial-pathogen-diagnostics.pdf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 6: Load PDFs into docs (doc_id -> full text) using sample_papers\n",
        "\n",
        "import os\n",
        "import fitz  # PyMuPDF\n",
        "\n",
        "PDF_FOLDER = \"/content\"  # change if your PDFs are in a subfolder\n",
        "\n",
        "def load_docs_from_sample_papers(sample_papers, folder_path):\n",
        "    docs = {}\n",
        "    docs_meta = {}\n",
        "\n",
        "    for p in sample_papers:\n",
        "        fname = p[\"file\"]\n",
        "        pdf_path = os.path.join(folder_path, fname)\n",
        "\n",
        "        doc_id = os.path.splitext(fname)[0]  # filename without .pdf\n",
        "        docs_meta[doc_id] = {\n",
        "            \"title\": p.get(\"title\", \"\"),\n",
        "            \"year\": p.get(\"year\", None),\n",
        "            \"authors\": p.get(\"authors\", \"\"),\n",
        "            \"journal\": p.get(\"journal\", \"\")\n",
        "        }\n",
        "\n",
        "        if not os.path.exists(pdf_path):\n",
        "            print(f\"âŒ Missing file: {pdf_path}\")\n",
        "            continue\n",
        "\n",
        "        pdf = fitz.open(pdf_path)\n",
        "        text = \"\\n\".join(page.get_text(\"text\") for page in pdf).strip()\n",
        "        pdf.close()\n",
        "\n",
        "        if text:\n",
        "            docs[doc_id] = text\n",
        "        else:\n",
        "            print(f\"âš ï¸ Empty text extracted: {fname}\")\n",
        "\n",
        "    return docs, docs_meta\n",
        "\n",
        "docs, docs_meta = load_docs_from_sample_papers(sample_papers, PDF_FOLDER)\n",
        "print(f\"âœ… Loaded docs: {len(docs)} / {len(sample_papers)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ka2aEOAOgS2_",
        "outputId": "e2b875a5-b0e6-4a47-8133-2b08fb37fa9b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Loaded docs: 5 / 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 7: Build the required index (term -> DocIDs) + build FAISS embeddings store (doc-level)\n",
        "\n",
        "# 1) Build inverted index (term -> DocIDs)\n",
        "inv_index = InvertedIndexStore()\n",
        "\n",
        "for doc_id, text in docs.items():\n",
        "    terms = preprocess_text(text)   # uses custom stopwords + stemming\n",
        "    for t in set(terms):            # presence only (not frequency)\n",
        "        inv_index.add_occurrence(t, doc_id)\n",
        "\n",
        "print(f\"âœ… Inverted index built. Unique terms: {inv_index.count_terms()}\")\n",
        "\n",
        "# 2) Build embeddings + FAISS (one vector per doc)\n",
        "doc_ids = list(docs.keys())\n",
        "texts = [docs[d] for d in doc_ids]\n",
        "\n",
        "emb = embed_model.encode(texts, convert_to_numpy=True, normalize_embeddings=True).astype(\"float32\")\n",
        "\n",
        "vector_dim = emb.shape[1]\n",
        "faiss_index = faiss.IndexFlatIP(vector_dim)  # cosine similarity via normalized embeddings\n",
        "faiss_index.add(emb)\n",
        "\n",
        "# parallel arrays for retrieval results\n",
        "vector_doc_ids = doc_ids\n",
        "vector_texts = texts\n",
        "\n",
        "print(f\"âœ… FAISS built. Vectors: {faiss_index.ntotal} | dim={vector_dim}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wyo0irOJLhRE",
        "outputId": "d958df40-9fbf-4ebe-a1ce-2477106b40e3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ“¦ InvertedIndexStore initialized\n",
            "âœ… Inverted index built. Unique terms: 5120\n",
            "âœ… FAISS built. Vectors: 5 | dim=384\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 8: Export + quick preview of the required index format (term + DocIDs)\n",
        "\n",
        "records = inv_index.to_required_format()\n",
        "\n",
        "print(f\"âœ… Index records created: {len(records)} terms\")\n",
        "print(\"Preview (first 10):\")\n",
        "for row in records[:10]:\n",
        "    print(row)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brXIuzKlggIm",
        "outputId": "058f3abc-bb8d-433d-d206-8a06e191dc71"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Index records created: 5120 terms\n",
            "Preview (first 10):\n",
            "{'term': 'aab', 'DocIDs': ['plants-09-00623']}\n",
            "{'term': 'aamra', 'DocIDs': ['jof-07-00900']}\n",
            "{'term': 'abad', 'DocIDs': ['jof-07-00900', 'plants-09-00623']}\n",
            "{'term': 'abbrevi', 'DocIDs': ['actanaturae_11026']}\n",
            "{'term': 'abd', 'DocIDs': ['actanaturae_11026', 'jof-07-00900']}\n",
            "{'term': 'abdallah', 'DocIDs': ['jof-07-00900']}\n",
            "{'term': 'abdel', 'DocIDs': ['jof-07-00900']}\n",
            "{'term': 'abdelkhalek', 'DocIDs': ['jof-07-00900']}\n",
            "{'term': 'abdellatef', 'DocIDs': ['jof-07-00900']}\n",
            "{'term': 'abdelrahman', 'DocIDs': ['jof-07-00900']}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 8: Sanity checks + index preview (NO PlantDiseaseIndexRAG)\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "print(\"âœ… Sanity checks:\")\n",
        "\n",
        "# 1) Documents\n",
        "print(\"Docs loaded:\", len(docs))\n",
        "assert len(docs) > 0, \"No documents loaded!\"\n",
        "\n",
        "# 2) Inverted index\n",
        "num_terms = inv_index.count_terms()\n",
        "print(\"Unique terms in index:\", num_terms)\n",
        "assert num_terms > 0, \"Index is empty!\"\n",
        "\n",
        "# 3) FAISS\n",
        "print(\"FAISS vectors:\", faiss_index.ntotal)\n",
        "assert faiss_index.ntotal == len(docs), \"FAISS vectors != docs count\"\n",
        "\n",
        "# 4) Export index in REQUIRED schema\n",
        "records = inv_index.to_required_format()\n",
        "df_index = pd.DataFrame(records)\n",
        "\n",
        "print(\"\\nâœ… Index preview (first 5 rows):\")\n",
        "display(df_index.head(5))\n",
        "\n",
        "print(\"\\nâœ… CELL 8 completed successfully\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 345
        },
        "id": "NV-M3w56g0pw",
        "outputId": "a8ccb9c4-ba32-4ddc-e110-a4ea1f5d899e"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Sanity checks:\n",
            "Docs loaded: 5\n",
            "Unique terms in index: 5120\n",
            "FAISS vectors: 5\n",
            "\n",
            "âœ… Index preview (first 5 rows):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "      term                             DocIDs\n",
              "0      aab                  [plants-09-00623]\n",
              "1    aamra                     [jof-07-00900]\n",
              "2     abad    [jof-07-00900, plants-09-00623]\n",
              "3  abbrevi                [actanaturae_11026]\n",
              "4      abd  [actanaturae_11026, jof-07-00900]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-cd043b6d-b274-4ab7-a062-5b79f1f6e523\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>term</th>\n",
              "      <th>DocIDs</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>aab</td>\n",
              "      <td>[plants-09-00623]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>aamra</td>\n",
              "      <td>[jof-07-00900]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>abad</td>\n",
              "      <td>[jof-07-00900, plants-09-00623]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>abbrevi</td>\n",
              "      <td>[actanaturae_11026]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>abd</td>\n",
              "      <td>[actanaturae_11026, jof-07-00900]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cd043b6d-b274-4ab7-a062-5b79f1f6e523')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-cd043b6d-b274-4ab7-a062-5b79f1f6e523 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-cd043b6d-b274-4ab7-a062-5b79f1f6e523');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-95e9c995-e6bb-46f2-86f2-0ee070f65218\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-95e9c995-e6bb-46f2-86f2-0ee070f65218')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-95e9c995-e6bb-46f2-86f2-0ee070f65218 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"print(\\\"\\\\n\\u2705 CELL 8 completed successfully\\\")\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"term\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"aamra\",\n          \"abd\",\n          \"abad\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"DocIDs\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "âœ… CELL 8 completed successfully\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 9: Embedding-based retrieval (FAISS) for a user query (no OpenAI yet)\n",
        "\n",
        "def retrieve_top_docs(query: str, top_k: int = 5):\n",
        "    if faiss_index is None or faiss_index.ntotal == 0:\n",
        "        return \"FAISS index is empty. Build vectors first.\"\n",
        "\n",
        "    q_emb = embed_model.encode([query], convert_to_numpy=True, normalize_embeddings=True).astype(\"float32\")\n",
        "    distances, indices = faiss_index.search(q_emb, top_k)\n",
        "\n",
        "    lines = []\n",
        "    lines.append(f\"Query: {query}\")\n",
        "    lines.append(\"=\" * 60)\n",
        "\n",
        "    for rank, idx in enumerate(indices[0], start=1):\n",
        "        if idx == -1:\n",
        "            continue\n",
        "        doc_id = vector_doc_ids[idx]\n",
        "        title = docs_meta.get(doc_id, {}).get(\"title\", \"\")\n",
        "        text = vector_texts[idx]\n",
        "        snippet = re.sub(r\"\\s+\", \" \", text)[:350]\n",
        "        score = float(distances[0][rank - 1])\n",
        "\n",
        "        lines.append(f\"{rank}) {doc_id} | {title} | similarity: {score:.4f}\")\n",
        "        lines.append(f\"Snippet: {snippet}...\")\n",
        "        lines.append(\"-\" * 60)\n",
        "\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "print(\"âœ… Retrieval function ready\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gDJK3udPfGLt",
        "outputId": "81a1e4c0-f826-44e8-8c9a-87ae4748cb0a"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… Retrieval function ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 10: RAG-style output (retrieval + \"enriched\" answer without OpenAI)\n",
        "# We will: retrieve top docs, then produce a simple enriched response by extracting key sentences.\n",
        "\n",
        "def split_sentences(text: str):\n",
        "    # simple sentence split (good enough for baseline)\n",
        "    parts = re.split(r'(?<=[.!?])\\s+', re.sub(r\"\\s+\", \" \", text).strip())\n",
        "    return [s for s in parts if len(s) > 30]\n",
        "\n",
        "def rag_answer_without_llm(query: str, top_k: int = 3, max_sentences_per_doc: int = 2):\n",
        "    if faiss_index is None or faiss_index.ntotal == 0:\n",
        "        return \"FAISS index is empty. Build vectors first.\"\n",
        "\n",
        "    q_emb = embed_model.encode([query], convert_to_numpy=True, normalize_embeddings=True).astype(\"float32\")\n",
        "    distances, indices = faiss_index.search(q_emb, top_k)\n",
        "\n",
        "    lines = []\n",
        "    lines.append(f\"Query: {query}\")\n",
        "    lines.append(\"=\" * 60)\n",
        "\n",
        "    # Retrieval section\n",
        "    lines.append(\"Top retrieved documents:\")\n",
        "    retrieved = []\n",
        "    for rank, idx in enumerate(indices[0], start=1):\n",
        "        if idx == -1:\n",
        "            continue\n",
        "        doc_id = vector_doc_ids[idx]\n",
        "        title = docs_meta.get(doc_id, {}).get(\"title\", \"\")\n",
        "        score = float(distances[0][rank - 1])\n",
        "        retrieved.append((doc_id, title, score))\n",
        "        lines.append(f\"{rank}) {doc_id} | {title} | similarity: {score:.4f}\")\n",
        "    lines.append(\"=\" * 60)\n",
        "\n",
        "    # Enriched response (extractive, no LLM)\n",
        "    lines.append(\"Enriched response (extractive, no LLM):\")\n",
        "    q_terms = set(preprocess_text(query))\n",
        "\n",
        "    for doc_id, title, score in retrieved:\n",
        "        text = docs[doc_id]\n",
        "        sents = split_sentences(text)\n",
        "\n",
        "        # score sentences by overlap with query terms (stems)\n",
        "        scored = []\n",
        "        for s in sents:\n",
        "            s_terms = set(preprocess_text(s))\n",
        "            overlap = len(q_terms & s_terms)\n",
        "            if overlap > 0:\n",
        "                scored.append((overlap, s))\n",
        "\n",
        "        scored.sort(key=lambda x: x[0], reverse=True)\n",
        "        best = [s for _, s in scored[:max_sentences_per_doc]]\n",
        "\n",
        "        lines.append(f\"- Source: {doc_id} | {title}\")\n",
        "        if best:\n",
        "            for b in best:\n",
        "                lines.append(f\"  â€¢ {b}\")\n",
        "        else:\n",
        "            lines.append(\"  â€¢ (No strong matching sentences found)\")\n",
        "        lines.append(\"-\" * 60)\n",
        "\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "print(\"âœ… RAG-style (no OpenAI) function ready\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NIPiXHAolYpt",
        "outputId": "6bba71b5-910c-421c-9207-2f4bdf19447e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… RAG-style (no OpenAI) function ready\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 11: Quick demo (edit the query text)\n",
        "\n",
        "print(retrieve_top_docs(\"how to detect plant diseases using sensors and ai\", top_k=3))\n",
        "print()\n",
        "print(rag_answer_without_llm(\"how to detect plant diseases using sensors and ai\", top_k=3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a9-53EC4lxNh",
        "outputId": "1b23722e-9b63-4312-b11a-fd3d813e0042"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Query: how to detect plant diseases using sensors and ai\n",
            "============================================================\n",
            "1) s41598-025-98454-6 | AI-IoT Based Smart Agriculture Pivot for Plant Diseases Detection and Treatment | similarity: 0.5921\n",
            "Snippet: AI-IoT based smart agriculture pivot for plant diseases detection and treatment Amin S. Ibrahim1, Saeed Mohsen 2,3ï€ª, I. M. Selim4, Roobaea Alroobaea 5, Majed Alsafyani5, Abdullah M. Baqasah6 & Mohamed Eassa7,8 There are some key problems faced in modern agriculture that IoT-based smart farming. These problems such shortage of water, plant diseases,...\n",
            "------------------------------------------------------------\n",
            "2) actanaturae_11026 | Infectious Plant Diseases: Etiology, Current Status, Problems and Prospects in Plant Protection | similarity: 0.4710\n",
            "Snippet: 46 | ACTA NATURAE | VOL. 12 â„– 3 (46) 2020 REVIEWS ABSTRACT In recent years, there has been an increase in the number of diseases caused by bacterial, fungal, and viral infections. Infections affect plants at different stages of agricultural production. Depending on weather conditions and the phytosanitary condition of crops, the prevalence of disea...\n",
            "------------------------------------------------------------\n",
            "3) plants-09-00623 | The Potential Risk of Plant-Virus Disease Initiation by Infected Tomatoes | similarity: 0.3993\n",
            "Snippet: plants Article The Potential Risk of Plant-Virus Disease Initiation by Infected Tomatoes Chen Klap 1,2, Neta Luria 1, Elisheva Smith 1, Elena Bakelman 1, Eduard Belausov 3, Orly Laskar 4, Oded Lachman 1, Amit Gal-On 1 and Aviv Dombrovsky 1,* 1 Department of Plant Pathology and Weed Research, Agricultural Research Organization, The Volcani Center, 6...\n",
            "------------------------------------------------------------\n",
            "\n",
            "Query: how to detect plant diseases using sensors and ai\n",
            "============================================================\n",
            "Top retrieved documents:\n",
            "1) s41598-025-98454-6 | AI-IoT Based Smart Agriculture Pivot for Plant Diseases Detection and Treatment | similarity: 0.5921\n",
            "2) actanaturae_11026 | Infectious Plant Diseases: Etiology, Current Status, Problems and Prospects in Plant Protection | similarity: 0.4710\n",
            "3) plants-09-00623 | The Potential Risk of Plant-Virus Disease Initiation by Infected Tomatoes | similarity: 0.3993\n",
            "============================================================\n",
            "Enriched response (extractive, no LLM):\n",
            "- Source: s41598-025-98454-6 | AI-IoT Based Smart Agriculture Pivot for Plant Diseases Detection and Treatment\n",
            "  â€¢ For both water irrigation and fertilization without plant diseases detection, Badreldeen et al.29 updated the central pivot system (CPS) using an IoT technology by adding the rain sensor and humidity sensor to the system to improve water irrigation management and save water resources.\n",
            "  â€¢ For the plant diseases detection, the paper augments a dataset of 25,940 images to classify 11-classes of plant leaves using a pre-trained ResNet50 model, which scores the testing accuracy of 99.8%, compared to other traditional works.\n",
            "------------------------------------------------------------\n",
            "- Source: actanaturae_11026 | Infectious Plant Diseases: Etiology, Current Status, Problems and Prospects in Plant Protection\n",
            "  â€¢ Identification of phytopathogens Early diagnosis of plant diseases is a key factor that determines the timely use of protective measures and, as a result, determines the yield and quality of crop products.\n",
            "  â€¢ Chemical control Chemical control plays a crucial role in preventing loss- es associated with plant diseases, especially with the advent of numerous fungicides with selective toxicity, which expands possibilities for using them in targeted fashion.\n",
            "------------------------------------------------------------\n",
            "- Source: plants-09-00623 | The Potential Risk of Plant-Virus Disease Initiation by Infected Tomatoes\n",
            "  â€¢ In a biological assay testing the contribution of traded infected tomatoes to the establishment of tomato plant disease, we applied direct and indirect inoculation modes using Tm-22-resistant tomato plants.\n",
            "  â€¢ Detection of pepino mosaic virus (PepMV) and tomato brown rugose fruit virus (ToBRFV) in leaf samples of tomato plants following four inoculation modes using enzyme linked immunosorbent assay (ELISA).\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 12: Evaluation / sanity checks (index + FAISS + stopwords + stemming)\n",
        "\n",
        "def evaluate_system():\n",
        "    lines = []\n",
        "    lines.append(\"=== EVALUATION (Sanity Checks) ===\")\n",
        "\n",
        "    # Docs\n",
        "    num_docs = len(docs) if isinstance(docs, dict) else 0\n",
        "    lines.append(f\"Docs loaded: {num_docs}\")\n",
        "    if num_docs == 0:\n",
        "        lines.append(\"âŒ No documents loaded. Check PDF_FOLDER path and filenames in sample_papers.\")\n",
        "        return \"\\n\".join(lines)\n",
        "\n",
        "    # Index\n",
        "    num_terms = inv_index.count_terms() if 'inv_index' in globals() else 0\n",
        "    lines.append(f\"Unique terms in inverted index: {num_terms}\")\n",
        "    if num_terms == 0:\n",
        "        lines.append(\"âŒ Index is empty. Check preprocess_text() and PDF text extraction.\")\n",
        "        return \"\\n\".join(lines)\n",
        "\n",
        "    # FAISS\n",
        "    faiss_total = faiss_index.ntotal if faiss_index is not None else 0\n",
        "    lines.append(f\"FAISS vectors: {faiss_total}\")\n",
        "    if faiss_total != num_docs:\n",
        "        lines.append(f\"âš ï¸ FAISS vectors ({faiss_total}) != docs ({num_docs}). Check embedding build step.\")\n",
        "\n",
        "    # Stopwords + stemming check on a tiny sample\n",
        "    sample_doc_id = next(iter(docs.keys()))\n",
        "    sample_text = docs[sample_doc_id][:800]\n",
        "    terms = preprocess_text(sample_text)\n",
        "\n",
        "    lines.append(f\"Sample doc_id: {sample_doc_id}\")\n",
        "    lines.append(f\"Sample extracted chars (first 80): {repr(docs[sample_doc_id][:80])}\")\n",
        "    lines.append(f\"Preprocess produced {len(terms)} terms from first 800 chars.\")\n",
        "    lines.append(f\"First 25 terms (stems): {terms[:25]}\")\n",
        "\n",
        "    # Check a few stopwords are removed\n",
        "    test_sentence = \"This is a simple test of the system and the index.\"\n",
        "    test_terms = preprocess_text(test_sentence)\n",
        "    lines.append(f\"Stopword test input: {test_sentence}\")\n",
        "    lines.append(f\"Stopword test output terms: {test_terms}\")\n",
        "    if any(w in test_terms for w in [\"the\", \"is\", \"and\", \"this\"]):\n",
        "        lines.append(\"âš ï¸ Some stopwords may still be appearing. Check CUSTOM_STOPWORDS and token filtering.\")\n",
        "    else:\n",
        "        lines.append(\"âœ… Stopwords appear to be removed (basic check).\")\n",
        "\n",
        "    # Quick retrieval check\n",
        "    q = \"plant disease detection\"\n",
        "    preview = retrieve_top_docs(q, top_k=2)\n",
        "    lines.append(\"Retrieval check (top 2):\")\n",
        "    lines.append(preview)\n",
        "\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "print(evaluate_system())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6mAqMyfHmDX1",
        "outputId": "2a35c73f-9824-4f3c-c132-6f2e1cf77f4d"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== EVALUATION (Sanity Checks) ===\n",
            "Docs loaded: 5\n",
            "Unique terms in inverted index: 5120\n",
            "FAISS vectors: 5\n",
            "Sample doc_id: s41598-025-98454-6\n",
            "Sample extracted chars (first 80): 'AI-IoT based smart agriculture \\npivot for plant diseases detection \\nand treatmen'\n",
            "Preprocess produced 75 terms from first 800 chars.\n",
            "First 25 terms (stems): ['base', 'smart', 'agricultur', 'pivot', 'plant', 'diseas', 'detect', 'treatment', 'amin', 'saeed', 'mohsen', 'roobaea', 'alroobaea', 'maje', 'abdullah', 'moham', 'there', 'some', 'key', 'problem', 'face', 'modern', 'agricultur', 'smart', 'farm']\n",
            "Stopword test input: This is a simple test of the system and the index.\n",
            "Stopword test output terms: ['simpl', 'test', 'system', 'index']\n",
            "âœ… Stopwords appear to be removed (basic check).\n",
            "Retrieval check (top 2):\n",
            "Query: plant disease detection\n",
            "============================================================\n",
            "1) actanaturae_11026 | Infectious Plant Diseases: Etiology, Current Status, Problems and Prospects in Plant Protection | similarity: 0.5681\n",
            "Snippet: 46 | ACTA NATURAE | VOL. 12 â„– 3 (46) 2020 REVIEWS ABSTRACT In recent years, there has been an increase in the number of diseases caused by bacterial, fungal, and viral infections. Infections affect plants at different stages of agricultural production. Depending on weather conditions and the phytosanitary condition of crops, the prevalence of disea...\n",
            "------------------------------------------------------------\n",
            "2) plants-09-00623 | The Potential Risk of Plant-Virus Disease Initiation by Infected Tomatoes | similarity: 0.5149\n",
            "Snippet: plants Article The Potential Risk of Plant-Virus Disease Initiation by Infected Tomatoes Chen Klap 1,2, Neta Luria 1, Elisheva Smith 1, Elena Bakelman 1, Eduard Belausov 3, Orly Laskar 4, Oded Lachman 1, Amit Gal-On 1 and Aviv Dombrovsky 1,* 1 Department of Plant Pathology and Weed Research, Agricultural Research Organization, The Volcani Center, 6...\n",
            "------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gXs6Q5xFmM4E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}