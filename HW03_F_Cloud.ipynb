{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Asaad972/CollabFirstNoteBook/blob/main/HW03_F_Cloud.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcwcS_-VsXcf"
      },
      "outputs": [],
      "source": [
        "# CELL 1: Minimal package installation (only if missing)\n",
        "import importlib.util, sys, subprocess\n",
        "\n",
        "def ensure(pkg, import_name=None):\n",
        "    name = import_name or pkg\n",
        "    if importlib.util.find_spec(name) is None:\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg])\n",
        "\n",
        "# Usually already installed in Colab, but keep safe:\n",
        "ensure(\"pandas\", \"pandas\")\n",
        "\n",
        "# Check if installiation is not done\n",
        "ensure(\"nltk\", \"nltk\")\n",
        "ensure(\"sentence-transformers\", \"sentence_transformers\")\n",
        "ensure(\"faiss-cpu\", \"faiss\")\n",
        "ensure(\"pymupdf\", \"fitz\")\n",
        "\n",
        "\n",
        "print(\" Dependencies ready\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 2: Imports + NLTK resources (run once per runtime)\n",
        "\n",
        "import requests\n",
        "import re\n",
        "from collections import defaultdict\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import google.generativeai as genai\n",
        "import textwrap\n",
        "\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import defaultdict\n",
        "\n",
        "from sentence_transformers import SentenceTransformer\n",
        "import faiss\n",
        "\n",
        "# NLTK downloads (required for stopwords/tokenizer/lemmatizer)\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"wordnet\")\n",
        "nltk.download(\"omw-1.4\")\n",
        "nltk.download(\"punkt_tab\")\n",
        "\n",
        "print(\" Imports ready + NLTK resources downloaded\")\n"
      ],
      "metadata": {
        "id": "2wDldDHHb8tY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 3: Store Classes (Vector Store + Inverted Index)\n",
        "# =====================================================\n",
        "\"\"\"\n",
        " CELL 3: STORE CLASSES\n",
        "- SimpleVectorStore: stores embeddings + documents + metadatas + ids (like Tirgul 7)\n",
        "- InvertedIndexStore: stores required index schema term -> DocIDs (homework requirement)\n",
        "\"\"\"\n",
        "\n",
        "# Vector Store (similar to Tirgul 7) # Meaning search\n",
        "class SimpleVectorStore:\n",
        "    \"\"\"Simple in-memory vector store (fallback)\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.documents = []\n",
        "        self.embeddings = []   # list of numpy arrays\n",
        "        self.metadatas = []\n",
        "        self.ids = []\n",
        "        print(\" SimpleVectorStore initialized\")\n",
        "\n",
        "    def add(self, embeddings, documents, metadatas, ids):\n",
        "        # Ensure numpy arrays\n",
        "        embeddings = [np.asarray(e, dtype=np.float32) for e in embeddings]\n",
        "        self.embeddings.extend(embeddings)\n",
        "        self.documents.extend(documents)\n",
        "        self.metadatas.extend(metadatas)\n",
        "        self.ids.extend(ids)\n",
        "        print(f\" Added {len(documents)} documents to simple vector store\")\n",
        "\n",
        "    def query(self, query_embeddings, n_results=5):\n",
        "        if not self.embeddings:\n",
        "            return {'ids': [[]], 'documents': [[]], 'metadatas': [[]], 'distances': [[]]}\n",
        "\n",
        "        q = np.asarray(query_embeddings[0], dtype=np.float32)\n",
        "\n",
        "        E = np.vstack(self.embeddings)  # shape: (N, d)\n",
        "\n",
        "        # cosine similarity without sklearn\n",
        "        q_norm = np.linalg.norm(q) + 1e-12\n",
        "        E_norm = np.linalg.norm(E, axis=1) + 1e-12\n",
        "        sims = (E @ q) / (E_norm * q_norm)\n",
        "\n",
        "        top_idx = np.argsort(sims)[::-1][:n_results]\n",
        "\n",
        "        return {\n",
        "            'ids': [[self.ids[i] for i in top_idx]],\n",
        "            'documents': [[self.documents[i] for i in top_idx]],\n",
        "            'metadatas': [[self.metadatas[i] for i in top_idx]],\n",
        "            'distances': [[float(1 - sims[i]) for i in top_idx]]  # distance-like\n",
        "        }\n",
        "\n",
        "    def count(self):\n",
        "        return len(self.documents)\n",
        "\n",
        "\n",
        "# Inverted Index # Keyboard search\n",
        "class InvertedIndexStore:\n",
        "    \"\"\"Required structure: term -> DocIDs\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.term_to_docids = defaultdict(set)\n",
        "        print(\" InvertedIndexStore initialized\")\n",
        "\n",
        "    def add_occurrence(self, term: str, doc_id: str):\n",
        "        self.term_to_docids[term].add(doc_id)\n",
        "\n",
        "    def get_docids(self, term: str):\n",
        "        return sorted(self.term_to_docids.get(term, set()))\n",
        "\n",
        "    def count_terms(self) -> int:\n",
        "        return len(self.term_to_docids)\n",
        "\n",
        "    def to_required_format(self):\n",
        "        # [{\"term\": ..., \"DocIDs\": [...]}, ...]\n",
        "        return [{\"term\": t, \"DocIDs\": sorted(list(docids))}\n",
        "                for t, docids in sorted(self.term_to_docids.items())]\n",
        "\n",
        "\n",
        "print(\" Store classes + Inverted index classes defined\")"
      ],
      "metadata": {
        "id": "H6h6ichmcgHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 4: Core setup (custom stopwords + stemming + embedding model + FAISS)\n",
        "\n",
        "# We remove these words because they are very frequent function words (articles, prepositions, pronouns).\n",
        "# They usually do not add topic meaning, but they increase index size and add noise to retrieval.\n",
        "CUSTOM_STOPWORDS = {\n",
        "    \"the\",\"a\",\"an\",\"and\",\"or\",\"but\",\n",
        "    \"to\",\"of\",\"in\",\"on\",\"at\",\"for\",\"from\",\"by\",\"with\",\"as\",\n",
        "    \"is\",\"are\",\"was\",\"were\",\"be\",\"been\",\"being\",\n",
        "    \"this\",\"that\",\"these\",\"those\",\n",
        "    \"it\",\"its\",\"they\",\"them\",\"their\",\"we\",\"our\",\"you\",\"your\",\n",
        "    \"i\",\"me\",\"my\",\"he\",\"him\",\"his\",\"she\",\"her\",\n",
        "    \"not\",\"no\",\"do\",\"does\",\"did\",\"doing\"\n",
        "}\n",
        "\n",
        "# Chops off word endings to find the \"root\" (stem)\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def preprocess_text(text: str):\n",
        "    \"\"\"\n",
        "    Returns list of terms for indexing:\n",
        "    - lowercase\n",
        "    - tokenize\n",
        "    - keep alphabetic tokens only\n",
        "    - remove custom stopwords\n",
        "    - apply stemming\n",
        "    \"\"\"\n",
        "    text = text.lower()\n",
        "    tokens = word_tokenize(text)\n",
        "    terms = []\n",
        "    for tok in tokens:\n",
        "        if tok.isalpha() and tok not in CUSTOM_STOPWORDS:\n",
        "            terms.append(stemmer.stem(tok))\n",
        "    return terms\n",
        "\n",
        "# --- Embedding model (for semantic retrieval) ---\n",
        "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# --- FAISS index (stores embeddings for doc-level retrieval) ---\n",
        "faiss_index = None\n",
        "vector_dim = None\n",
        "\n",
        "# Parallel stores (FAISS row -> doc data)\n",
        "vector_doc_ids = []   # doc_id\n",
        "vector_texts = []     # full doc text\n",
        "\n",
        "print(\" Core setup ready (custom stopwords + stemming + embeddings + FAISS)\")"
      ],
      "metadata": {
        "id": "eOcug8jcPQ7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- NEW CELL: GEMINI SETUP (Universal Fix) ---\n",
        "\n",
        "MY_API_KEY = \"AIzaSyBKnL3B2VmXrojL4SC6AHudALVoPcEBS9k\"\n",
        "\n",
        "genai.configure(api_key=MY_API_KEY)\n",
        "\n",
        "# 1. DYNAMICALLY FIND A WORKING MODEL\n",
        "print(\"ðŸ”„ Connecting to Google API to find valid models...\")\n",
        "valid_model_name = \"\"\n",
        "\n",
        "try:\n",
        "    for m in genai.list_models():\n",
        "        if 'generateContent' in m.supported_generation_methods:\n",
        "            # We prefer 1.5 Flash, but we will take ANYTHING that works\n",
        "            if \"flash\" in m.name:\n",
        "                valid_model_name = m.name\n",
        "                break # Found the best one, stop looking\n",
        "            elif \"gemini-pro\" in m.name and not valid_model_name:\n",
        "                valid_model_name = m.name\n",
        "\n",
        "    if not valid_model_name:\n",
        "        # Fallback if the loop found nothing\n",
        "        valid_model_name = \"models/gemini-pro\"\n",
        "\n",
        "    print(f\"âœ… FOUND VALID MODEL: {valid_model_name}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"âŒ Error listing models: {e}\")\n",
        "    print(\"Defaulting to 'models/gemini-pro'\")\n",
        "    valid_model_name = \"models/gemini-pro\"\n",
        "\n",
        "\n",
        "def ask_gemini(context, user_question):\n",
        "    if not context: return \"No relevant info found.\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Answer based ONLY on this context:\n",
        "    {context}\n",
        "\n",
        "    Question: {user_question}\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        # Use the variable we found earlier\n",
        "        model = genai.GenerativeModel(valid_model_name)\n",
        "        response = model.generate_content(prompt)\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "print(\"âœ… Setup Complete. Ready to run RAG.\")"
      ],
      "metadata": {
        "id": "zPjbOgTkMFZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 5: Wikipedia source links (seed documents for the corpus)\n",
        "\n",
        "wiki_links = [\n",
        "    \"https://en.wikipedia.org/wiki/Plant_disease\",\n",
        "    \"https://en.wikipedia.org/wiki/Plant_pathology\",\n",
        "    \"https://en.wikipedia.org/wiki/Fungus\",\n",
        "    \"https://en.wikipedia.org/wiki/Bacterial_wilt\",\n",
        "    \"https://en.wikipedia.org/wiki/Powdery_mildew\"\n",
        "]\n",
        "\n",
        "print(\"Wikipedia links used:\")\n",
        "for i, link in enumerate(wiki_links, 1):\n",
        "    print(f\"{i}. {link}\")\n"
      ],
      "metadata": {
        "id": "F5Swqy3GdK37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 6: Load documents from Wikipedia (API fetch + normalization + metadata)\n",
        "\n",
        "WIKI_API = \"https://en.wikipedia.org/w/api.php\"\n",
        "\n",
        "# Wikipedia blocks requests without a proper User-Agent sometimes\n",
        "HEADERS = {\n",
        "    \"User-Agent\": \"HW02-Cloud-RAG/1.0 (student project; contact: abrahem.sadekk@gmail.com)\"\n",
        "}\n",
        "\n",
        "# Extract the actual topic from a messy link\n",
        "def title_from_wiki_url(url: str) -> str:\n",
        "    if \"/wiki/\" not in url:\n",
        "        raise ValueError(f\"Unsupported Wikipedia URL: {url}\")\n",
        "    title = url.split(\"/wiki/\", 1)[1]\n",
        "    title = title.split(\"#\", 1)[0]      # remove anchors\n",
        "    title = title.replace(\"_\", \" \")\n",
        "    return title\n",
        "\n",
        "# This is the \"Worker Bee\" function. It talks to Wikipedia's servers\n",
        "def fetch_page_extract_by_title(title: str):\n",
        "    # This dictionary tells Wikipedia exactly what you want\n",
        "    params = {\n",
        "        \"action\": \"query\",\n",
        "        \"format\": \"json\",\n",
        "        \"prop\": \"extracts|info\",\n",
        "        \"titles\": title,\n",
        "        \"inprop\": \"url\",\n",
        "        \"explaintext\": True,\n",
        "        \"redirects\": 1,   # follow redirects\n",
        "        \"origin\": \"*\"     # helps in some environments\n",
        "    }\n",
        "    r = requests.get(WIKI_API, params=params, headers=HEADERS, timeout=30)\n",
        "    r.raise_for_status()\n",
        "\n",
        "    pages = r.json()[\"query\"][\"pages\"]\n",
        "    page = next(iter(pages.values()))\n",
        "\n",
        "    # Handle missing page\n",
        "    if \"missing\" in page:\n",
        "        return {\"pageid\": None, \"title\": title, \"url\": \"\", \"text\": \"\"}\n",
        "\n",
        "    return {\n",
        "        \"pageid\": page.get(\"pageid\"),\n",
        "        \"title\": page.get(\"title\", title),\n",
        "        \"url\": page.get(\"fullurl\", \"\"),\n",
        "        \"text\": page.get(\"extract\", \"\")\n",
        "    }\n",
        "\n",
        "def slugify(s: str) -> str:\n",
        "    s = s.strip().lower()\n",
        "    s = re.sub(r\"[^a-z0-9]+\", \"-\", s)\n",
        "    return s.strip(\"-\")\n",
        "\n",
        "def load_docs_from_wiki_links(wiki_links):\n",
        "    docs = {}\n",
        "    docs_meta = {}\n",
        "\n",
        "    for url in wiki_links:\n",
        "        title = title_from_wiki_url(url)\n",
        "        data = fetch_page_extract_by_title(title)\n",
        "\n",
        "        text = (data.get(\"text\") or \"\").strip()\n",
        "        if not text:\n",
        "            print(f\"Empty/blocked page: {title} | {url}\")\n",
        "            continue\n",
        "\n",
        "        doc_id = f\"wiki_{slugify(data['title'])}\"\n",
        "        docs[doc_id] = text\n",
        "        docs_meta[doc_id] = {\n",
        "            \"title\": data[\"title\"],\n",
        "            \"url\": data.get(\"url\") or url,\n",
        "            \"source\": \"wikipedia\",\n",
        "            \"pageid\": data.get(\"pageid\"),\n",
        "        }\n",
        "\n",
        "        print(f\"Loaded: {data['title']} -> {doc_id} | chars={len(text)}\")\n",
        "\n",
        "    return docs, docs_meta\n",
        "\n",
        "docs, docs_meta = load_docs_from_wiki_links(wiki_links)\n",
        "print(\"Docs loaded:\", len(docs))\n"
      ],
      "metadata": {
        "id": "ka2aEOAOgS2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 7: Build the required index (term -> DocIDs) + build FAISS embeddings store (doc-level)\n",
        "\n",
        "# Build inverted index (term -> DocIDs) # For keyboard search\n",
        "inv_index = InvertedIndexStore()\n",
        "\n",
        "for doc_id, text in docs.items():\n",
        "    terms = preprocess_text(text)   # Clean the text (stemming, removing 'the', etc..)\n",
        "    for t in set(terms):            # presence only (not frequency)\n",
        "        inv_index.add_occurrence(t, doc_id)\n",
        "\n",
        "print(f\" Inverted index built. Unique terms: {inv_index.count_terms()}\")\n",
        "\n",
        "# Build embeddings + FAISS (one vector per doc) # For meanings search\n",
        "doc_ids = list(docs.keys())\n",
        "texts = [docs[d] for d in doc_ids]\n",
        "\n",
        "emb = embed_model.encode(texts, convert_to_numpy=True, normalize_embeddings=True).astype(\"float32\")\n",
        "\n",
        "vector_dim = emb.shape[1]\n",
        "faiss_index = faiss.IndexFlatIP(vector_dim)  # cosine similarity via normalized embeddings\n",
        "faiss_index.add(emb)\n",
        "\n",
        "# parallel arrays for retrieval results\n",
        "vector_doc_ids = doc_ids\n",
        "vector_texts = texts\n",
        "\n",
        "print(f\" FAISS built. Vectors: {faiss_index.ntotal} | dim={vector_dim}\")\n"
      ],
      "metadata": {
        "id": "x1SNUhlfQPfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 8: Firebase Initialization (Hybrid Safe Mode)\n",
        "\n",
        "!pip -q install firebase-admin\n",
        "\n",
        "import firebase_admin\n",
        "from firebase_admin import credentials, firestore\n",
        "import base64\n",
        "\n",
        "# --- 1. Public Configuration (Safe to share) ---\n",
        "# We keep the standard info visible so the code is easy to understand.\n",
        "config = {\n",
        "  \"type\": \"service_account\",\n",
        "  \"project_id\": \"hw02-cloud-inverted-index\",\n",
        "  \"private_key_id\": \"437db7abaab45e69cf2bf0c22aa8c2e23cbbc71e\",\n",
        "  \"client_email\": \"firebase-adminsdk-fbsvc@hw02-cloud-inverted-index.iam.gserviceaccount.com\",\n",
        "  \"client_id\": \"105185385505390955098\",\n",
        "  \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n",
        "  \"token_uri\": \"https://oauth2.googleapis.com/token\",\n",
        "  \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n",
        "  \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/firebase-adminsdk-fbsvc%40hw02-cloud-inverted-index.iam.gserviceaccount.com\",\n",
        "  \"universe_domain\": \"googleapis.com\"\n",
        "}\n",
        "\n",
        "# --- 2. Private Key (Hidden) ---\n",
        "# Paste the string you generated in Step 1 here.\n",
        "scrambled_key = \"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\"\n",
        "\n",
        "try:\n",
        "    # We unlock the key and add it to the config\n",
        "    config[\"private_key\"] = base64.b64decode(scrambled_key).decode('utf-8')\n",
        "\n",
        "    # Initialize Firebase\n",
        "    cred = credentials.Certificate(config)\n",
        "\n",
        "    if not firebase_admin._apps:\n",
        "        firebase_admin.initialize_app(cred)\n",
        "\n",
        "    db = firestore.client()\n",
        "    print(\"Firestore connected successfully to:\", db.project)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")"
      ],
      "metadata": {
        "id": "z3PfU1boz_l-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 9: Upload inverted index to Firestore (cloud storage of term -> DocIDs)\n",
        "\n",
        "# Fix 1: Removed unused 'ArrayUnion' import\n",
        "# Fix 2: Added 'db' as an argument to link explicitly to Cell 8\n",
        "\n",
        "def upload_inverted_index(inv_index, db_client, collection_name=\"inverted_index\", batch_size=400):\n",
        "    \"\"\"\n",
        "    Uploads the inverted index to Firestore.\n",
        "    \"\"\"\n",
        "    col = db_client.collection(collection_name)\n",
        "\n",
        "    # Ensure your inv_index object has this method.\n",
        "    # If inv_index is just a plain dict, use: records = [{\"term\": t, \"DocIDs\": d} for t, d in inv_index.items()]\n",
        "    records = inv_index.to_required_format()\n",
        "\n",
        "    batch = db_client.batch()\n",
        "    ops = 0\n",
        "\n",
        "    for r in records:\n",
        "        term = r[\"term\"]\n",
        "        doc_ids = r[\"DocIDs\"]\n",
        "\n",
        "        # Fix 3: SANITIZE THE ID.\n",
        "        # Firestore IDs cannot contain '/'. We replace it with '_' or simple URL encoding.\n",
        "        safe_term = term.replace(\"/\", \"_\")\n",
        "\n",
        "        # Limit length to 1500 bytes (Firestore limit per ID)\n",
        "        doc_id = safe_term[:1500]\n",
        "\n",
        "        ref = col.document(doc_id)\n",
        "        batch.set(ref, {\n",
        "            \"term\": term,         # Store original term inside the document\n",
        "            \"doc_ids\": doc_ids,\n",
        "            \"df\": len(doc_ids),\n",
        "        })\n",
        "\n",
        "        ops += 1\n",
        "        if ops >= batch_size:\n",
        "            batch.commit()\n",
        "            batch = db_client.batch()\n",
        "            ops = 0\n",
        "\n",
        "    if ops > 0:\n",
        "        batch.commit()\n",
        "\n",
        "    print(f\"Uploaded {len(records)} terms to Firestore collection '{collection_name}'\")\n",
        "\n",
        "# Execute the upload passing the 'db' from Cell 8\n",
        "upload_inverted_index(inv_index, db)"
      ],
      "metadata": {
        "id": "3GMKBFBw1sdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 10: Upload Wikipedia document metadata to Firestore (documents collection)\n",
        "\n",
        "def upload_wiki_meta(docs_meta, collection_name=\"documents\", batch_size=400):\n",
        "    \"\"\"\n",
        "    Uploads Wikipedia document metadata to Firestore.\n",
        "\n",
        "    Each document is stored as:\n",
        "      documents/{doc_id}\n",
        "\n",
        "    Stored fields:\n",
        "      - doc_id  : your internal document ID (e.g., wiki_plant-disease)\n",
        "      - title   : Wikipedia page title\n",
        "      - url     : Wikipedia page URL\n",
        "      - source  : \"wikipedia\"\n",
        "      - pageid  : Wikipedia page id (if available)\n",
        "\n",
        "    This does NOT upload the full article text; it only uploads metadata.\n",
        "    \"\"\"\n",
        "    col = db.collection(collection_name)\n",
        "\n",
        "    batch = db.batch()\n",
        "    ops = 0\n",
        "\n",
        "    for doc_id, meta in docs_meta.items():\n",
        "        ref = col.document(doc_id)\n",
        "        batch.set(ref, {\n",
        "            \"doc_id\": doc_id,\n",
        "            \"title\": meta.get(\"title\", \"\"),\n",
        "            \"url\": meta.get(\"url\", \"\"),\n",
        "            \"source\": meta.get(\"source\", \"wikipedia\"),\n",
        "            \"pageid\": meta.get(\"pageid\", None),\n",
        "        }, merge=True)\n",
        "\n",
        "        ops += 1\n",
        "        if ops >= batch_size:\n",
        "            batch.commit()\n",
        "            batch = db.batch()\n",
        "            ops = 0\n",
        "\n",
        "    if ops > 0:\n",
        "        batch.commit()\n",
        "\n",
        "    print(f\"Uploaded {len(docs_meta)} wiki docs to '{collection_name}'\")\n",
        "\n",
        "# Upload metadata for the loaded Wikipedia docs\n",
        "upload_wiki_meta(docs_meta)\n"
      ],
      "metadata": {
        "id": "Al003f-n5Ubq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 11: Embedding-based document retrieval using FAISS (semantic search)\n",
        "\n",
        "def retrieve_top_docs(query: str, top_k: int = 5):\n",
        "    \"\"\"\n",
        "    Retrieves the top-K most relevant documents for a user query using\n",
        "    vector embeddings and FAISS similarity search.\n",
        "\n",
        "    This function:\n",
        "      1) Embeds the query using the same embedding model as the documents\n",
        "      2) Searches the FAISS index using cosine similarity\n",
        "      3) Returns ranked documents with titles, similarity scores, and text snippets\n",
        "\n",
        "    Note: This is retrieval only (no generation / no LLM).\n",
        "    \"\"\"\n",
        "    if faiss_index is None or faiss_index.ntotal == 0:\n",
        "        return \"FAISS index is empty. Build vectors first.\"\n",
        "\n",
        "    # Embed and normalize the query\n",
        "    q_emb = embed_model.encode(\n",
        "        [query],\n",
        "        convert_to_numpy=True,\n",
        "        normalize_embeddings=True\n",
        "    ).astype(\"float32\")\n",
        "\n",
        "    # Search FAISS index\n",
        "    distances, indices = faiss_index.search(q_emb, top_k)\n",
        "\n",
        "    lines = []\n",
        "    lines.append(f\"Query: {query}\")\n",
        "    lines.append(\"=\" * 60)\n",
        "\n",
        "    # Format ranked results\n",
        "    for rank, idx in enumerate(indices[0], start=1):\n",
        "        if idx == -1:\n",
        "            continue\n",
        "\n",
        "        doc_id = vector_doc_ids[idx]\n",
        "        title = docs_meta.get(doc_id, {}).get(\"title\", \"\")\n",
        "        text = vector_texts[idx]\n",
        "        snippet = re.sub(r\"\\s+\", \" \", text)[:350]\n",
        "        score = float(distances[0][rank - 1])\n",
        "\n",
        "        lines.append(f\"{rank}) {doc_id} | {title} | similarity: {score:.4f}\")\n",
        "        lines.append(f\"Snippet: {snippet}...\")\n",
        "        lines.append(\"-\" * 60)\n",
        "\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "print(\"Retrieval function ready\")"
      ],
      "metadata": {
        "id": "dIvaQbcITaV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 12: RAG-style output (retrieval + \"enriched\" answer without OpenAI)\n",
        "# We will: retrieve top docs, then produce a simple enriched response by extracting key sentences.\n",
        "\n",
        "def split_sentences(text: str):\n",
        "    # simple sentence split (good enough for baseline)\n",
        "    parts = re.split(r'(?<=[.!?])\\s+', re.sub(r\"\\s+\", \" \", text).strip())\n",
        "    return [s for s in parts if len(s) > 30]\n",
        "\n",
        "def rag_answer_without_llm(query: str, top_k: int = 3, max_sentences_per_doc: int = 2):\n",
        "    if faiss_index is None or faiss_index.ntotal == 0:\n",
        "        return \"FAISS index is empty. Build vectors first.\"\n",
        "\n",
        "    q_emb = embed_model.encode([query], convert_to_numpy=True, normalize_embeddings=True).astype(\"float32\")\n",
        "    distances, indices = faiss_index.search(q_emb, top_k)\n",
        "\n",
        "    lines = []\n",
        "    lines.append(f\"Query: {query}\")\n",
        "    lines.append(\"=\" * 60)\n",
        "\n",
        "    # Retrieval section\n",
        "    lines.append(\"Top retrieved documents:\")\n",
        "    retrieved = []\n",
        "    for rank, idx in enumerate(indices[0], start=1):\n",
        "        if idx == -1:\n",
        "            continue\n",
        "        doc_id = vector_doc_ids[idx]\n",
        "        title = docs_meta.get(doc_id, {}).get(\"title\", \"\")\n",
        "        score = float(distances[0][rank - 1])\n",
        "        retrieved.append((doc_id, title, score))\n",
        "        lines.append(f\"{rank}) {doc_id} | {title} | similarity: {score:.4f}\")\n",
        "    lines.append(\"=\" * 60)\n",
        "\n",
        "    # Enriched response (extractive, no LLM)\n",
        "    lines.append(\"Enriched response (extractive, no LLM):\")\n",
        "    q_terms = set(preprocess_text(query))\n",
        "\n",
        "    for doc_id, title, score in retrieved:\n",
        "        text = docs[doc_id]\n",
        "        sents = split_sentences(text)\n",
        "\n",
        "        # score sentences by overlap with query terms (stems)\n",
        "        scored = []\n",
        "        for s in sents:\n",
        "            s_terms = set(preprocess_text(s))\n",
        "            overlap = len(q_terms & s_terms)\n",
        "            if overlap > 0:\n",
        "                scored.append((overlap, s))\n",
        "\n",
        "        scored.sort(key=lambda x: x[0], reverse=True)\n",
        "        best = [s for _, s in scored[:max_sentences_per_doc]]\n",
        "\n",
        "        lines.append(f\"- Source: {doc_id} | {title}\")\n",
        "        if best:\n",
        "            for b in best:\n",
        "                lines.append(f\"  â€¢ {b}\")\n",
        "        else:\n",
        "            lines.append(\"  â€¢ (No strong matching sentences found)\")\n",
        "        lines.append(\"-\" * 60)\n",
        "\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "print(\" RAG-style (no OpenAI) function ready\")\n"
      ],
      "metadata": {
        "id": "yNqRTEkVPTuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 13: Quick demo (edit the query text)\n",
        "\n",
        "print(retrieve_top_docs(\"how to detect plant diseases using sensors and ai\", top_k=3))\n",
        "print()\n",
        "print(rag_answer_without_llm(\"how to detect plant diseases using sensors and ai\", top_k=3))\n"
      ],
      "metadata": {
        "id": "UXh_buFURvu4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 14: Interactive RAG Chatbot (Using Extractive RAG Filter)\n",
        "\n",
        "def start_interactive_chat():\n",
        "    print(\"ðŸ¤– AI Plant Doctor is ready! (Type 'exit' or 'quit' to stop)\")\n",
        "    print(\"-\" * 60)\n",
        "\n",
        "    while True:\n",
        "        # 1. Ask the user for input\n",
        "        try:\n",
        "            user_query = input(\"\\nâ“ Enter your question: \").strip()\n",
        "        except EOFError:\n",
        "            break\n",
        "\n",
        "        if user_query.lower() in ['exit', 'quit', 'stop', 'bye']:\n",
        "            print(\"\\nðŸ‘‹ Goodbye!\")\n",
        "            break\n",
        "\n",
        "        if not user_query:\n",
        "            continue\n",
        "\n",
        "        # 2. Get the \"Rough Draft\" answer from your extractive function\n",
        "        print(f\"   ðŸ”Ž extracting key sentences (rag_answer_without_llm)...\")\n",
        "\n",
        "        # We increase top_k slightly so Gemini has enough context to work with\n",
        "        rough_draft_context = rag_answer_without_llm(user_query, top_k=5)\n",
        "\n",
        "        if \"FAISS index is empty\" in rough_draft_context:\n",
        "            print(\"âš ï¸ Error: FAISS index is empty. Please run Cell 7 first.\")\n",
        "            break\n",
        "\n",
        "        # 3. Feed that \"Rough Draft\" into Gemini to make it natural and polite\n",
        "        print(f\"   ðŸ§  Asking Gemini to refine the answer...\")\n",
        "        final_answer = ask_gemini(rough_draft_context, user_query)\n",
        "\n",
        "        # 4. Print the final result\n",
        "        print(\"\\n\" + \"=\"*60)\n",
        "        print(f\"ðŸ’¡ ANSWER:\\n{final_answer}\")\n",
        "        print(\"=\"*60)\n",
        "\n",
        "# Start the chat loop\n",
        "#start_interactive_chat()"
      ],
      "metadata": {
        "id": "DmuNzhgLPp8C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##CHATBOT Gemini"
      ],
      "metadata": {
        "id": "jpGcLICllG41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 3: Define \"Patterns\" (System Instructions)\n",
        "\n",
        "# We tell Gemini how to behave to mimic the NLTK patterns\n",
        "system_instruction = \"\"\"\n",
        "You are a helpful chatbot.\n",
        "- If user says 'hi' or 'hello', answer: 'Hello there!'\n",
        "- If user asks 'what is your name', answer: 'I am a Gemini Chatbot.'\n",
        "- If user asks 'how are you', answer: 'I am doing well, thank you!'\n",
        "- Otherwise, answer helpfully and concisely.\n",
        "\"\"\"\n",
        "\n",
        "print(\"âœ… Step 3: Patterns defined.\")"
      ],
      "metadata": {
        "id": "t_ggrDW5lJSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# STEP 4: Build the Chatbot\n",
        "\n",
        "# We use the 'valid_model_name' from your existing setup code\n",
        "model = genai.GenerativeModel(\n",
        "    valid_model_name,\n",
        "    system_instruction=system_instruction\n",
        ")\n",
        "\n",
        "# Start the chat session (equivalent to initializing NLTK Chat)\n",
        "chat_session = model.start_chat(history=[])\n",
        "\n",
        "print(f\"âœ… Step 4: Chatbot built using {valid_model_name}.\")"
      ],
      "metadata": {
        "id": "kL6voX75lKJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#FROM NOW ON. ASAAD'S PART"
      ],
      "metadata": {
        "id": "ZJL2UYRadFR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install firebase-admin ipywidgets matplotlib\n",
        "\n",
        "import firebase_admin\n",
        "from firebase_admin import credentials, firestore\n",
        "from google.colab import userdata  # Import userdata\n",
        "import json\n",
        "\n",
        "# Check if Firebase is already running to avoid re-initialization error\n",
        "if not firebase_admin._apps:\n",
        "    # Use Colab Secrets instead of a file path\n",
        "    key_content = userdata.get('FIREBASE_KEY')\n",
        "    key_dict = json.loads(key_content)\n",
        "    cred = credentials.Certificate(key_dict)\n",
        "    firebase_admin.initialize_app(cred)\n",
        "\n",
        "# Get the client (works even if initialized in previous cells)\n",
        "db = firestore.client()\n",
        "# --- FIX END ---\n",
        "\n",
        "print(\"âœ… Connected to Firestore in project:\", db.project)"
      ],
      "metadata": {
        "id": "DmIJXYU1dIqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "BASE_URL = \"https://server-cloud-v645.onrender.com\"\n",
        "\n",
        "def fetch_history(feed: str, limit: int = 30) -> pd.DataFrame:\n",
        "    \"\"\"Fetch IoT history from course server. Returns DataFrame with created_at,value.\"\"\"\n",
        "    resp = requests.get(f\"{BASE_URL}/history\", params={\"feed\": feed, \"limit\": int(limit)}, timeout=120)\n",
        "    resp.raise_for_status()\n",
        "    data = resp.json()\n",
        "    if \"data\" not in data:\n",
        "        raise ValueError(f\"Server error: {data}\")\n",
        "\n",
        "    df = pd.DataFrame(data[\"data\"])\n",
        "    df[\"created_at\"] = pd.to_datetime(df[\"created_at\"], errors=\"coerce\")\n",
        "    df[\"value\"] = pd.to_numeric(df[\"value\"], errors=\"coerce\")\n",
        "    df = df.dropna(subset=[\"created_at\", \"value\"]).sort_values(\"created_at\")\n",
        "    return df\n"
      ],
      "metadata": {
        "id": "WfyJ7ggJnUBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip -q install transformers timm pillow torch --upgrade\n",
        "import io\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime, timezone\n",
        "from PIL import Image\n",
        "# hugging face import\n",
        "from transformers import pipeline\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 1. MODEL SETUP\n",
        "# ---------------------------------------------------------------------\n",
        "MODEL_ID = \"linkanjarad/mobilenet_v2_1.0_224-plant-disease-identification\"\n",
        "# load hugging face model here\n",
        "clf = pipeline(\"image-classification\", model=MODEL_ID)\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 2. DESIGN CSS (Bigger Stats, Side-by-Side Tables)\n",
        "# ---------------------------------------------------------------------\n",
        "CSS = \"\"\"\n",
        "<style>\n",
        "@import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap');\n",
        "\n",
        ":root {\n",
        "    --bg-app: #f8fafc;\n",
        "    --surface: #ffffff;\n",
        "    --primary: #4f46e5;       /* Indigo */\n",
        "    --primary-hover: #4338ca;\n",
        "    --text-main: #0f172a;\n",
        "    --text-sub: #64748b;\n",
        "    --border: #e2e8f0;\n",
        "    --radius-l: 24px;\n",
        "    --radius-m: 16px;\n",
        "    --radius-s: 12px;\n",
        "    --shadow-card: 0 4px 6px -1px rgba(0, 0, 0, 0.05), 0 2px 4px -1px rgba(0, 0, 0, 0.03);\n",
        "}\n",
        "\n",
        ".jupyter-widgets, .widget-area {\n",
        "    font-family: 'Inter', system-ui, sans-serif !important;\n",
        "    color: var(--text-main);\n",
        "}\n",
        "\n",
        "/* App Wrapper */\n",
        ".app-shell {\n",
        "    background: var(--bg-app);\n",
        "    padding: 24px;\n",
        "    border-radius: 0 0 var(--radius-l) var(--radius-l);\n",
        "    border: 1px solid var(--border);\n",
        "}\n",
        "\n",
        "/* Modern Card */\n",
        ".gemini-card {\n",
        "    background: var(--surface);\n",
        "    border-radius: var(--radius-l);\n",
        "    padding: 32px;\n",
        "    border: 1px solid var(--border);\n",
        "    box-shadow: var(--shadow-card);\n",
        "    margin-bottom: 24px;\n",
        "}\n",
        ".gemini-card h2 {\n",
        "    color: var(--text-main);\n",
        "    margin: 0 0 8px 0;\n",
        "    font-size: 22px;\n",
        "    font-weight: 700;\n",
        "}\n",
        ".gemini-card p {\n",
        "    color: var(--text-sub);\n",
        "    font-size: 14px;\n",
        "    margin: 0 0 24px 0;\n",
        "}\n",
        "\n",
        "/* Tabs */\n",
        ".p-TabBar-tab {\n",
        "    background: transparent !important;\n",
        "    border: none !important;\n",
        "    color: var(--text-sub) !important;\n",
        "    font-weight: 600 !important;\n",
        "    padding: 12px 24px !important;\n",
        "    border-radius: var(--radius-s) !important;\n",
        "    margin-right: 4px !important;\n",
        "    transition: all 0.2s;\n",
        "}\n",
        ".p-TabBar-tab:hover {\n",
        "    background: #f1f5f9 !important;\n",
        "    color: var(--text-main) !important;\n",
        "}\n",
        ".p-TabBar-tab.p-mod-current {\n",
        "    color: var(--primary) !important;\n",
        "    background: #eef2ff !important;\n",
        "}\n",
        "\n",
        "/* Inputs */\n",
        ".widget-text input,\n",
        ".widget-textarea textarea,\n",
        ".widget-dropdown select,\n",
        ".widget-readout {\n",
        "    background: #ffffff !important;\n",
        "    color: var(--text-main) !important;\n",
        "    border: 1px solid #cbd5e1 !important;\n",
        "    border-radius: var(--radius-s) !important;\n",
        "    padding: 12px !important;\n",
        "    font-size: 14px !important;\n",
        "    transition: all 0.2s;\n",
        "}\n",
        ".widget-text input:focus,\n",
        ".widget-textarea textarea:focus {\n",
        "    border-color: var(--primary) !important;\n",
        "    box-shadow: 0 0 0 3px rgba(79, 70, 229, 0.15) !important;\n",
        "}\n",
        "\n",
        "/* Buttons */\n",
        ".btn-primary button {\n",
        "    background: var(--primary) !important;\n",
        "    color: white !important;\n",
        "    border-radius: 50px !important;\n",
        "    font-weight: 600 !important;\n",
        "    border: none !important;\n",
        "    padding: 10px 24px !important;\n",
        "}\n",
        ".btn-warning button {\n",
        "    background: #f59e0b !important;\n",
        "    color: white !important;\n",
        "    border-radius: 50px !important;\n",
        "    font-weight: 600 !important;\n",
        "    border: none !important;\n",
        "}\n",
        "\n",
        "/* Chat Window Container */\n",
        ".chat-window {\n",
        "    background: #ffffff;\n",
        "    border: 1px solid var(--border);\n",
        "    border-radius: var(--radius-m);\n",
        "    padding: 20px;\n",
        "    background-image: radial-gradient(#f1f5f9 1px, transparent 1px);\n",
        "    background-size: 20px 20px;\n",
        "    height: 400px;\n",
        "    overflow-y: auto;\n",
        "}\n",
        "\n",
        "/* BIGGER STAT BOXES */\n",
        ".stat-box {\n",
        "    background: #f8fafc;\n",
        "    border: 1px solid #e2e8f0;\n",
        "    padding: 25px; /* Increased padding */\n",
        "    border-radius: 16px;\n",
        "    text-align: center;\n",
        "    flex: 1;\n",
        "    box-shadow: 0 2px 4px rgba(0,0,0,0.02);\n",
        "}\n",
        ".stat-title {\n",
        "    font-size: 14px;\n",
        "    color: #64748b;\n",
        "    font-weight: 700;\n",
        "    text-transform: uppercase;\n",
        "    letter-spacing: 0.5px;\n",
        "}\n",
        ".stat-val {\n",
        "    font-size: 32px; /* Bigger font */\n",
        "    font-weight: 800;\n",
        "    color: #0f172a;\n",
        "    margin: 10px 0;\n",
        "}\n",
        "\n",
        "/* Upload Widget */\n",
        ".widget-upload > label {\n",
        "    width: 100%;\n",
        "    border: 2px dashed #cbd5e1;\n",
        "    border-radius: var(--radius-m);\n",
        "    background: #f8fafc;\n",
        "    padding: 32px;\n",
        "    text-align: center;\n",
        "    cursor: pointer;\n",
        "    font-weight: 600;\n",
        "    color: var(--primary);\n",
        "}\n",
        "\n",
        "/* Side by Side Tables container */\n",
        ".tables-container {\n",
        "    display: flex;\n",
        "    gap: 15px;\n",
        "    width: 100%;\n",
        "    overflow-x: auto;\n",
        "}\n",
        "</style>\n",
        "\"\"\"\n",
        "display(widgets.HTML(CSS))\n",
        "\n",
        "def create_card(title, subtitle, children):\n",
        "    header = widgets.HTML(f\"<h2>{title}</h2><p>{subtitle}</p>\")\n",
        "    box = widgets.VBox([header] + children)\n",
        "    box.add_class(\"gemini-card\")\n",
        "    return box\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# SCREEN A â€” PLANT DIAGNOSTIC\n",
        "# ---------------------------------------------------------------------\n",
        "a_out = widgets.Output()\n",
        "\n",
        "a_name = widgets.Text(\n",
        "    placeholder=\"Plant species (e.g. Tomato)\",\n",
        "    description=\"Name:\",\n",
        "    style={'description_width': '60px'},\n",
        "    layout=widgets.Layout(width='100%')\n",
        ")\n",
        "a_uploader = widgets.FileUpload(\n",
        "    accept=\"image/*\",\n",
        "    multiple=False,\n",
        "    description=\"ðŸ“‚ Upload Leaf Photo\"\n",
        ")\n",
        "a_uploader.layout = widgets.Layout(width='100%')\n",
        "a_btn = widgets.Button(description=\"Analyze & Save\", layout=widgets.Layout(width='100%', height='48px'))\n",
        "a_btn.add_class(\"btn-primary\")\n",
        "\n",
        "def on_plant_upload(change):\n",
        "    with a_out:\n",
        "        clear_output()\n",
        "        if not a_uploader.value: return\n",
        "        fname, f = list(a_uploader.value.items())[0]\n",
        "        display(widgets.Image(value=f[\"content\"], width=320, layout=widgets.Layout(border='4px solid #f1f5f9', border_radius='12px')))\n",
        "\n",
        "a_uploader.observe(on_plant_upload, names=\"value\")\n",
        "\n",
        "def run_plant_analysis(_):\n",
        "    with a_out:\n",
        "        clear_output()\n",
        "        if not a_uploader.value: return\n",
        "        fname, f = list(a_uploader.value.items())[0]\n",
        "        img = Image.open(io.BytesIO(f[\"content\"])).convert(\"RGB\")\n",
        "        preds = clf(img)\n",
        "        top = preds[0]\n",
        "        clear_output()\n",
        "        display(widgets.Image(value=f[\"content\"], width=320, layout=widgets.Layout(border_radius='12px')))\n",
        "\n",
        "        healthy = \"healthy\" in top[\"label\"].lower()\n",
        "        bg = \"#ecfdf5\" if healthy else \"#fef2f2\"\n",
        "        border = \"#10b981\" if healthy else \"#ef4444\"\n",
        "        text_col = \"#047857\" if healthy else \"#b91c1c\"\n",
        "\n",
        "        display(widgets.HTML(f\"\"\"\n",
        "            <div style=\"background:{bg}; color:{text_col}; padding:24px; border-radius:16px; margin-top:20px; border: 1px solid {border}; text-align:center;\">\n",
        "                <h3 style=\"margin:0;\">{top['label'].replace('_',' ').title()}</h3>\n",
        "                <p>Confidence: {top['score']*100:.2f}%</p>\n",
        "            </div>\n",
        "        \"\"\"))\n",
        "        try:\n",
        "            db.collection(\"plant_images\").add({ \"plant\": a_name.value, \"file\": fname, \"prediction\": top[\"label\"], \"score\": float(top[\"score\"]), \"time\": datetime.now(timezone.utc) })\n",
        "        except: pass\n",
        "\n",
        "a_btn.on_click(run_plant_analysis)\n",
        "screenA = create_card(\"Plant Diagnostic\", \"Identify plant diseases using AI.\", [a_name, widgets.HTML(\"<div style='height:15px'></div>\"), a_uploader, widgets.HTML(\"<div style='height:20px'></div>\"), a_btn, a_out])\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# SCREEN B â€” IOT DATA (BIG BOXES & SIDE-BY-SIDE TABLES)\n",
        "# ---------------------------------------------------------------------\n",
        "b_out = widgets.Output()\n",
        "\n",
        "b_limit = widgets.IntSlider(\n",
        "    value=5, min=1, max=20, step=1,\n",
        "    description=\"Rows:\",\n",
        "    style={'description_width': '60px'},\n",
        "    layout=widgets.Layout(width='60%')\n",
        ")\n",
        "b_btn = widgets.Button(\n",
        "    description=\"Fetch Data\",\n",
        "    layout=widgets.Layout(width='50%', height='48px')\n",
        ")\n",
        "b_btn.add_class(\"btn-primary\")\n",
        "\n",
        "def fetch_sensor_data(_):\n",
        "    with b_out:\n",
        "        clear_output()\n",
        "        try:\n",
        "            # Fetch all 3\n",
        "            df_soil = fetch_history(\"soil\", b_limit.value)\n",
        "            df_hum = fetch_history(\"humidity\", b_limit.value)\n",
        "            df_temp = fetch_history(\"temperature\", b_limit.value)\n",
        "\n",
        "            # Get latest values safely\n",
        "            l_soil = df_soil[\"value\"].iloc[-1] if not df_soil.empty else \"N/A\"\n",
        "            l_hum = df_hum[\"value\"].iloc[-1] if not df_hum.empty else \"N/A\"\n",
        "            l_temp = df_temp[\"value\"].iloc[-1] if not df_temp.empty else \"N/A\"\n",
        "\n",
        "            # 1. BIGGER STAT CARDS\n",
        "            display(widgets.HTML(f\"\"\"\n",
        "            <div style=\"display:flex; gap:20px; margin-bottom:30px;\">\n",
        "                <div class=\"stat-box\">\n",
        "                    <div class=\"stat-title\">ðŸŒ± Soil Moisture</div>\n",
        "                    <div class=\"stat-val\">{l_soil}%</div>\n",
        "                </div>\n",
        "                <div class=\"stat-box\">\n",
        "                    <div class=\"stat-title\">ðŸ’§ Humidity</div>\n",
        "                    <div class=\"stat-val\">{l_hum}%</div>\n",
        "                </div>\n",
        "                <div class=\"stat-box\">\n",
        "                    <div class=\"stat-title\">ðŸŒ¡ï¸ Temperature</div>\n",
        "                    <div class=\"stat-val\">{l_temp}Â°C</div>\n",
        "                </div>\n",
        "            </div>\n",
        "            \"\"\"))\n",
        "\n",
        "            # 2. SIDE BY SIDE TABLES (Using HBox of Outputs)\n",
        "            out1 = widgets.Output()\n",
        "            out2 = widgets.Output()\n",
        "            out3 = widgets.Output()\n",
        "\n",
        "            with out1:\n",
        "                print(\"--- Soil ---\")\n",
        "                display(df_soil)\n",
        "            with out2:\n",
        "                print(\"--- Humidity ---\")\n",
        "                display(df_hum)\n",
        "            with out3:\n",
        "                print(\"--- Temp ---\")\n",
        "                display(df_temp)\n",
        "\n",
        "            # Put them in an HBox\n",
        "            hbox = widgets.HBox([out1, out2, out3])\n",
        "            hbox.layout = widgets.Layout(justify_content=\"space-between\", width=\"100%\")\n",
        "            display(hbox)\n",
        "\n",
        "        except NameError:\n",
        "            print(\"â„¹ 'fetch_history' is not defined.\")\n",
        "        except Exception as e:\n",
        "            print(\"âŒ Error fetching data:\", e)\n",
        "\n",
        "b_btn.on_click(fetch_sensor_data)\n",
        "\n",
        "screenB = create_card(\n",
        "    \"IoT Data Logs\",\n",
        "    \"Real-time sensor feeds.\",\n",
        "    [\n",
        "        b_limit,\n",
        "        widgets.HTML(\"<div style='height:16px;'></div>\"),\n",
        "        b_btn,\n",
        "        b_out,\n",
        "    ]\n",
        ")\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# SCREEN C â€” DASHBOARD (Unchanged)\n",
        "# ---------------------------------------------------------------------\n",
        "dash_out = widgets.Output()\n",
        "\n",
        "dash_limit = widgets.IntSlider(\n",
        "    value=30, min=10, max=200, step=10,\n",
        "    description=\"Range:\",\n",
        "    style={'description_width': '60px'},\n",
        "    layout=widgets.Layout(width='80%')\n",
        ")\n",
        "\n",
        "dash_btn = widgets.Button(\n",
        "    description=\"Update Dashboard\",\n",
        "    layout=widgets.Layout(width='60%', height='48px')\n",
        ")\n",
        "dash_btn.add_class(\"btn-warning\")\n",
        "\n",
        "def get_status_color(feed, val):\n",
        "    status = \"OK\"\n",
        "    if feed == \"soil\":\n",
        "        if val < 30: status = \"Critical\"\n",
        "        elif val < 45: status = \"Warning\"\n",
        "    elif feed == \"humidity\":\n",
        "        if val < 30: status = \"Warning\"\n",
        "    elif feed == \"temperature\":\n",
        "        if val < 10 or val > 35: status = \"Warning\"\n",
        "\n",
        "    if status == \"Critical\": return \"#ef4444\", \"Critical\"\n",
        "    if status == \"Warning\": return \"#f59e0b\", \"Warning\"\n",
        "    return \"#10b981\", \"OK\"\n",
        "\n",
        "def build_dashboard(_):\n",
        "    with dash_out:\n",
        "        clear_output()\n",
        "        try:\n",
        "            df_soil = fetch_history(\"soil\", dash_limit.value)\n",
        "            df_hum = fetch_history(\"humidity\", dash_limit.value)\n",
        "            df_temp = fetch_history(\"temperature\", dash_limit.value)\n",
        "        except Exception as e:\n",
        "            print(\"Error fetching data:\", e)\n",
        "            return\n",
        "\n",
        "        val_s = df_soil[\"value\"].iloc[-1]\n",
        "        val_h = df_hum[\"value\"].iloc[-1]\n",
        "        val_t = df_temp[\"value\"].iloc[-1]\n",
        "\n",
        "        col_s, stat_s = get_status_color(\"soil\", val_s)\n",
        "        col_h, stat_h = get_status_color(\"humidity\", val_h)\n",
        "        col_t, stat_t = get_status_color(\"temperature\", val_t)\n",
        "\n",
        "        display(widgets.HTML(f\"\"\"\n",
        "        <div style=\"display:flex; gap:10px; margin-bottom:20px; flex-wrap:wrap;\">\n",
        "            <div style=\"background:{col_s}; color:white; padding:8px 16px; border-radius:20px; font-weight:600; font-size:13px;\">Soil: {stat_s}</div>\n",
        "            <div style=\"background:{col_h}; color:white; padding:8px 16px; border-radius:20px; font-weight:600; font-size:13px;\">Humidity: {stat_h}</div>\n",
        "            <div style=\"background:{col_t}; color:white; padding:8px 16px; border-radius:20px; font-weight:600; font-size:13px;\">Temp: {stat_t}</div>\n",
        "        </div>\n",
        "        \"\"\"))\n",
        "\n",
        "        issues = []\n",
        "        if stat_s in [\"Critical\", \"Warning\"]: issues.append(\"low soil moisture\")\n",
        "        if stat_h in [\"Critical\", \"Warning\"]: issues.append(\"low humidity\")\n",
        "        if stat_t in [\"Critical\", \"Warning\"]: issues.append(\"extreme temperature\")\n",
        "\n",
        "        if issues:\n",
        "            display(widgets.HTML(\"<div style='color:#f59e0b; font-weight:600;'>ðŸ’¡ Generating AI Insight for issues...</div>\"))\n",
        "            query = f\"impact of {', '.join(issues)} on plant health\"\n",
        "            try:\n",
        "                insight = rag_answer_without_llm(query, top_k=1)\n",
        "                display(widgets.HTML(f\"\"\"\n",
        "                    <div style=\"background:#fffbeb; border-left:4px solid #f59e0b; padding:16px; border-radius:8px; margin-bottom:20px; color:#92400e;\">\n",
        "                        <b>AI Diagnosis:</b><br>{insight}\n",
        "                    </div>\n",
        "                \"\"\"))\n",
        "            except: pass\n",
        "\n",
        "        plt.style.use('default')\n",
        "        plt.figure(figsize=(10, 4))\n",
        "        plt.plot(df_soil[\"created_at\"], df_soil[\"value\"], marker=\"o\", label=\"Soil Moisture\", color=\"#8b5cf6\", linewidth=2)\n",
        "        plt.plot(df_hum[\"created_at\"], df_hum[\"value\"], marker=\"s\", label=\"Humidity\", color=\"#3b82f6\", linewidth=2)\n",
        "        plt.plot(df_temp[\"created_at\"], df_temp[\"value\"], marker=\"^\", label=\"Temperature\", color=\"#ef4444\", linewidth=2)\n",
        "\n",
        "        plt.title(\"Combined Environment Monitoring\", fontsize=12, fontweight='bold', color='#1e293b')\n",
        "        plt.xlabel(\"Time\", color='#64748b')\n",
        "        plt.ylabel(\"Value\", color='#64748b')\n",
        "        plt.grid(True, axis=\"y\", linestyle=\"--\", alpha=0.3)\n",
        "        plt.legend()\n",
        "        plt.xticks(rotation=30)\n",
        "        plt.gca().spines['top'].set_visible(False)\n",
        "        plt.gca().spines['right'].set_visible(False)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "dash_btn.on_click(build_dashboard)\n",
        "\n",
        "screenC = create_card(\"Live Dashboard\", \"Real-time visualization.\", [dash_limit, widgets.HTML(\"<div style='height:16px;'></div>\"), dash_btn, dash_out])\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# SCREEN D â€” SEARCH (RESTORED DETAILS)\n",
        "# ---------------------------------------------------------------------\n",
        "c_out = widgets.Output()\n",
        "index_box = widgets.Text(value=\"inverted_index\", description=\"Index:\", style={'description_width': '60px'}, layout=widgets.Layout(width=\"70%\"))\n",
        "query_box = widgets.Text(value=\"about\", description=\"Query:\", style={'description_width': '60px'}, layout=widgets.Layout(width=\"70%\"))\n",
        "search_btn = widgets.Button(description=\"Search DB\", layout=widgets.Layout(width='50%', height='48px', margin='10px 0 0 70px'))\n",
        "search_btn.add_class(\"btn-primary\")\n",
        "\n",
        "def search_inverted_index(index_name: str, term: str):\n",
        "    index_name = index_name.strip()\n",
        "    term = term.strip().lower()\n",
        "    if not index_name or not term:\n",
        "        return None, \"Enter both Index and Search.\"\n",
        "\n",
        "    doc = db.collection(index_name).document(term).get()\n",
        "    if doc.exists:\n",
        "        data = doc.to_dict() or {}\n",
        "        return {\n",
        "            \"term\": term,\n",
        "            \"df\": data.get(\"df\"),\n",
        "            \"doc_ids\": data.get(\"doc_ids\", [])\n",
        "        }, None\n",
        "\n",
        "    qs = list(db.collection(index_name).where(\"term\", \"==\", term).limit(1).stream())\n",
        "    if qs:\n",
        "        data = qs[0].to_dict() or {}\n",
        "        return {\n",
        "            \"term\": term,\n",
        "            \"df\": data.get(\"df\"),\n",
        "            \"doc_ids\": data.get(\"doc_ids\", [])\n",
        "        }, None\n",
        "\n",
        "    return None, f\"No results for '{term}' in '{index_name}'.\"\n",
        "\n",
        "def on_search_click(_):\n",
        "    with c_out:\n",
        "        clear_output()\n",
        "        try:\n",
        "            result, err = search_inverted_index(index_box.value, query_box.value)\n",
        "        except NameError:\n",
        "            print(\"â„¹ï¸ Firestore client 'db' is not defined.\")\n",
        "            return\n",
        "        if err:\n",
        "            print(err)\n",
        "            return\n",
        "\n",
        "        # FIXED: Explicitly showing Frequency (DF) and list of IDs\n",
        "        html = \"<ul style='padding-left:18px; color:#475569; max-height:100px; overflow-y:auto;'>\"\n",
        "        for did in result.get(\"doc_ids\", []):\n",
        "            html += f\"<li>{did}</li>\"\n",
        "        html += \"</ul>\"\n",
        "\n",
        "        display(widgets.HTML(f\"\"\"\n",
        "            <div style=\"background:#f8fafc; padding:20px; border-radius:12px; border:1px solid #e2e8f0;\">\n",
        "                <p style=\"margin:5px 0; font-size:16px;\"><b>Term:</b> <span style=\"color:#4f46e5; font-weight:bold;\">{result['term']}</span></p>\n",
        "                <p style=\"margin:5px 0; font-size:16px;\"><b>Mentioned:</b> <span style=\"font-weight:bold; color:#0f172a;\">{result.get('df', 0)} times</span> (Document Frequency)</p>\n",
        "                <div style=\"margin-top:15px; font-weight:600; color:#64748b; border-bottom:1px solid #e2e8f0; padding-bottom:5px;\">Found in Documents:</div>\n",
        "                {html}\n",
        "            </div>\n",
        "        \"\"\"))\n",
        "\n",
        "search_btn.on_click(on_search_click)\n",
        "screenD = create_card(\"Knowledge Search\", \"Query the Firestore index.\", [index_box, query_box, search_btn, c_out])\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# SCREEN E â€” CHAT (RAG)\n",
        "# ---------------------------------------------------------------------\n",
        "chat_out = widgets.Output()\n",
        "chat_out.add_class(\"chat-window\")\n",
        "chat_box = widgets.Textarea(placeholder=\"Ask about plant diseases... (Press Enter)\", layout=widgets.Layout(width=\"100%\", height=\"80px\"))\n",
        "send_btn = widgets.Button(description=\"Send\", layout=widgets.Layout(width=\"120px\", height=\"40px\"))\n",
        "send_btn.add_class(\"btn-primary\")\n",
        "clear_btn = widgets.Button(description=\"Clear\", layout=widgets.Layout(width=\"120px\", height=\"40px\"))\n",
        "status_line = widgets.HTML(\"\")\n",
        "\n",
        "def render_message(role, text):\n",
        "    align = \"flex-end\" if role == \"user\" else \"flex-start\"\n",
        "    bg = \"#4f46e5\" if role == \"user\" else \"#f8fafc\"\n",
        "    col = \"white\" if role == \"user\" else \"#1e293b\"\n",
        "    border = \"none\" if role == \"user\" else \"1px solid #e2e8f0\"\n",
        "\n",
        "    bubble = f\"\"\"<div style=\"display:flex; justify-content:{align}; margin:15px 0;\">\n",
        "          <div style=\"max-width:75%; background:{bg}; color:{col}; padding:12px 16px; border-radius:18px 18px 4px 18px; border:{border}; font-size:14px;\">{text}</div></div>\"\"\"\n",
        "    display(widgets.HTML(bubble))\n",
        "\n",
        "def handle_send(_=None):\n",
        "    q = chat_box.value.strip()\n",
        "    if not q: return\n",
        "    chat_box.value = \"\"\n",
        "    with chat_out: render_message(\"user\", q)\n",
        "    try:\n",
        "        status_line.value = \"<span style='color:#4f46e5; font-weight:600;'>ðŸ§  Thinking...</span>\"\n",
        "        rough = rag_answer_without_llm(q, top_k=5)\n",
        "        final = ask_gemini(rough, q)\n",
        "        status_line.value = \"\"\n",
        "        with chat_out: render_message(\"ai\", final)\n",
        "    except Exception as e:\n",
        "        status_line.value = \"\"\n",
        "        with chat_out: render_message(\"ai\", f\"Error: {e}\")\n",
        "\n",
        "def on_rag_enter(change):\n",
        "    if change[\"new\"].endswith(\"\\n\"):\n",
        "        chat_box.value = chat_box.value.strip()\n",
        "        handle_send()\n",
        "\n",
        "chat_box.observe(on_rag_enter, names=\"value\")\n",
        "send_btn.on_click(handle_send)\n",
        "clear_btn.on_click(lambda _: chat_out.clear_output())\n",
        "\n",
        "screenE = create_card(\"AI Assistant (RAG)\", \"Chat with your data.\", [chat_out, widgets.HTML(\"<div style='height:16px;'></div>\"), chat_box, widgets.HBox([send_btn, clear_btn]), status_line])\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# SCREEN F â€” GEMINI CHAT\n",
        "# ---------------------------------------------------------------------\n",
        "gem_out = widgets.Output()\n",
        "gem_out.add_class(\"chat-window\")\n",
        "gem_input = widgets.Textarea(placeholder=\"Ask Gemini... (Press Enter)\", layout=widgets.Layout(width=\"100%\", height=\"80px\"))\n",
        "gem_send = widgets.Button(description=\"Send\", layout=widgets.Layout(width=\"120px\", height=\"40px\"))\n",
        "gem_send.add_class(\"btn-primary\")\n",
        "gem_clear = widgets.Button(description=\"Clear\", layout=widgets.Layout(width=\"120px\", height=\"40px\"))\n",
        "gem_stat = widgets.HTML(\"\")\n",
        "\n",
        "def gem_logic(_=None):\n",
        "    q = gem_input.value.strip()\n",
        "    if not q: return\n",
        "    gem_input.value = \"\"\n",
        "    with gem_out: render_message(\"user\", q)\n",
        "    try:\n",
        "        gem_stat.value = \"<b style='color:#4f46e5'>Thinking...</b>\"\n",
        "        resp = chat_session.send_message(q)\n",
        "        gem_stat.value = \"\"\n",
        "        with gem_out: render_message(\"ai\", resp.text)\n",
        "    except Exception as e:\n",
        "        gem_stat.value = \"\"\n",
        "        with gem_out: render_message(\"ai\", f\"Error: {e}\")\n",
        "\n",
        "def on_gem_enter(change):\n",
        "    if change[\"new\"].endswith(\"\\n\"):\n",
        "        gem_input.value = gem_input.value.strip()\n",
        "        gem_logic()\n",
        "\n",
        "gem_input.observe(on_gem_enter, names=\"value\")\n",
        "gem_send.on_click(gem_logic)\n",
        "gem_clear.on_click(lambda _: gem_out.clear_output())\n",
        "\n",
        "screenF = create_card(\"Gemini Direct\", \"Clean workspace.\", [gem_out, widgets.HTML(\"<div style='height:16px;'></div>\"), gem_input, widgets.HBox([gem_send, gem_clear]), gem_stat])\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# FINAL ASSEMBLY\n",
        "# ---------------------------------------------------------------------\n",
        "tabs = widgets.Tab(children=[screenA, screenB, screenC, screenD, screenE, screenF])\n",
        "tabs.set_title(0, \"Diagnosis\")\n",
        "tabs.set_title(1, \"IoT Data\")\n",
        "tabs.set_title(2, \"Dashboard\")\n",
        "tabs.set_title(3, \"Search\")\n",
        "tabs.set_title(4, \"RAG Chat\")\n",
        "tabs.set_title(5, \"Gemini\")\n",
        "\n",
        "header = widgets.HTML(\n",
        "    \"\"\"<div style='display:flex; align-items:center; gap:12px; margin-bottom:20px; border-bottom:1px solid #e2e8f0; padding-bottom:20px;'>\n",
        "        <div style='width:40px; height:40px; background:#4f46e5; border-radius:10px; display:flex; align-items:center; justify-content:center; color:white; font-size:20px;'>ðŸŒ±</div>\n",
        "        <div><h1 style='margin:0; font-size:24px; color:#1e293b;'>PlantCare AI</h1></div>\n",
        "    </div>\"\"\"\n",
        ")\n",
        "\n",
        "app = widgets.VBox([header, tabs])\n",
        "app.add_class(\"app-shell\")\n",
        "display(app)"
      ],
      "metadata": {
        "id": "gBdLeLCp545B"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}