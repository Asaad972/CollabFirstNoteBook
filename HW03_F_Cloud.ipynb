{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Asaad972/CollabFirstNoteBook/blob/main/HW03_F_Cloud.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZcwcS_-VsXcf"
      },
      "outputs": [],
      "source": [
        "# CELL 1: Package Installation & Setup\n",
        "import importlib.util, sys, subprocess\n",
        "\n",
        "def ensure(pkg, import_name=None):\n",
        "    \"\"\"Checks if a package is installed; if not, installs it.\"\"\"\n",
        "    name = import_name or pkg\n",
        "    if importlib.util.find_spec(name) is None:\n",
        "        print(f\"Installing {pkg}...\")\n",
        "        subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", pkg])\n",
        "\n",
        "# 1. Core Data & ML\n",
        "ensure(\"pandas\", \"pandas\")\n",
        "ensure(\"numpy\", \"numpy\")\n",
        "ensure(\"sentence-transformers\", \"sentence_transformers\")\n",
        "ensure(\"faiss-cpu\", \"faiss\")\n",
        "ensure(\"pymupdf\", \"fitz\")       # For PDF reading (if used later)\n",
        "ensure(\"transformers\", \"transformers\")\n",
        "\n",
        "# 2. NLP\n",
        "ensure(\"nltk\", \"nltk\")\n",
        "\n",
        "# 3. UI & Visualization\n",
        "ensure(\"ipywidgets\", \"ipywidgets\")\n",
        "ensure(\"matplotlib\", \"matplotlib\")\n",
        "\n",
        "# 4. Cloud & Database\n",
        "ensure(\"firebase-admin\", \"firebase_admin\")\n",
        "\n",
        "print(\"‚úÖ Dependencies ready\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 2: Imports & Resources (Run once)\n",
        "\n",
        "# --- Standard Library ---\n",
        "import io\n",
        "import re\n",
        "import sys\n",
        "import json\n",
        "import base64\n",
        "import textwrap\n",
        "import requests\n",
        "from datetime import datetime, timezone\n",
        "from collections import defaultdict\n",
        "\n",
        "# --- Data Science & Math ---\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# --- Visualization & UI ---\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "# --- Machine Learning & AI ---\n",
        "import faiss\n",
        "import google.generativeai as genai\n",
        "from transformers import pipeline\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# --- Firebase & Cloud ---\n",
        "import firebase_admin\n",
        "from firebase_admin import credentials, firestore\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "# --- Time ---\n",
        "from datetime import datetime, timezone\n",
        "import time\n",
        "\n",
        "# --- NLP (NLTK) ---\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# --- Download NLTK Resources ---\n",
        "# Using quiet=True to keep output clean\n",
        "nltk.download(\"stopwords\", quiet=True)\n",
        "nltk.download(\"punkt\", quiet=True)\n",
        "nltk.download(\"wordnet\", quiet=True)\n",
        "nltk.download(\"omw-1.4\", quiet=True)\n",
        "nltk.download(\"punkt_tab\", quiet=True)\n",
        "\n",
        "print(\"‚úÖ Imports ready + NLTK resources downloaded\")"
      ],
      "metadata": {
        "id": "2wDldDHHb8tY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 3: Store Classes (Vector Store + Inverted Index)\n",
        "# =====================================================\n",
        "\n",
        "# Vector Store (Your original code, unchanged)\n",
        "class SimpleVectorStore:\n",
        "    \"\"\"Simple in-memory vector store (fallback)\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        self.documents = []\n",
        "        self.embeddings = []   # list of numpy arrays\n",
        "        self.metadatas = []\n",
        "        self.ids = []\n",
        "        print(\" SimpleVectorStore initialized\")\n",
        "\n",
        "    def add(self, embeddings, documents, metadatas, ids):\n",
        "        # Ensure numpy arrays\n",
        "        embeddings = [np.asarray(e, dtype=np.float32) for e in embeddings]\n",
        "        self.embeddings.extend(embeddings)\n",
        "        self.documents.extend(documents)\n",
        "        self.metadatas.extend(metadatas)\n",
        "        self.ids.extend(ids)\n",
        "        print(f\" Added {len(documents)} documents to simple vector store\")\n",
        "\n",
        "    def query(self, query_embeddings, n_results=5):\n",
        "        if not self.embeddings:\n",
        "            return {'ids': [[]], 'documents': [[]], 'metadatas': [[]], 'distances': [[]]}\n",
        "\n",
        "        q = np.asarray(query_embeddings[0], dtype=np.float32)\n",
        "        E = np.vstack(self.embeddings)  # shape: (N, d)\n",
        "\n",
        "        # cosine similarity without sklearn\n",
        "        q_norm = np.linalg.norm(q) + 1e-12\n",
        "        E_norm = np.linalg.norm(E, axis=1) + 1e-12\n",
        "        sims = (E @ q) / (E_norm * q_norm)\n",
        "\n",
        "        top_idx = np.argsort(sims)[::-1][:n_results]\n",
        "\n",
        "        return {\n",
        "            'ids': [[self.ids[i] for i in top_idx]],\n",
        "            'documents': [[self.documents[i] for i in top_idx]],\n",
        "            'metadatas': [[self.metadatas[i] for i in top_idx]],\n",
        "            'distances': [[float(1 - sims[i]) for i in top_idx]]  # distance-like\n",
        "        }\n",
        "\n",
        "    def count(self):\n",
        "        return len(self.documents)\n",
        "\n",
        "\n",
        "# Inverted Index (UPDATED with Tutorial Logic)\n",
        "class InvertedIndexStore:\n",
        "    \"\"\"\n",
        "    Updated Structure: term -> {doc_id: frequency}\n",
        "    Includes 'search' method for ranking by Matches + Frequency\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Maps term -> dictionary of {doc_id: count}\n",
        "        self.term_to_doc_freqs = defaultdict(lambda: defaultdict(int))\n",
        "        print(\" InvertedIndexStore initialized (Frequency Aware)\")\n",
        "\n",
        "    def add_occurrence(self, term: str, doc_id: str, count: int = 1):\n",
        "        # Store the frequency\n",
        "        self.term_to_doc_freqs[term][doc_id] += count\n",
        "\n",
        "    def get_docids(self, term: str):\n",
        "        return sorted(list(self.term_to_doc_freqs.get(term, {}).keys()))\n",
        "\n",
        "    def count_terms(self) -> int:\n",
        "        return len(self.term_to_doc_freqs)\n",
        "\n",
        "    def to_required_format(self):\n",
        "        # [{\"term\": ..., \"DocIDs\": [...]}, ...]\n",
        "        return [{\"term\": t, \"DocIDs\": sorted(list(doc_freqs.keys()))}\n",
        "                for t, doc_freqs in sorted(self.term_to_doc_freqs.items())]\n",
        "\n",
        "    def search(self, query_words, num_results=5):\n",
        "        \"\"\"\n",
        "        Rank docs by:\n",
        "        1. 'matches': Number of unique query terms found\n",
        "        2. 'total_freq': Total count of those terms\n",
        "        \"\"\"\n",
        "        if not query_words:\n",
        "            return []\n",
        "\n",
        "        # doc_id -> {'matches': 0, 'total_freq': 0}\n",
        "        doc_scores = defaultdict(lambda: {'matches': 0, 'total_freq': 0})\n",
        "\n",
        "        for word in query_words:\n",
        "            if word in self.term_to_doc_freqs:\n",
        "                for doc_id, freq in self.term_to_doc_freqs[word].items():\n",
        "                    doc_scores[doc_id]['matches'] += 1\n",
        "                    doc_scores[doc_id]['total_freq'] += freq\n",
        "\n",
        "        # Convert to list\n",
        "        ranked_results = [\n",
        "            (doc_id, scores['matches'], scores['total_freq'])\n",
        "            for doc_id, scores in doc_scores.items()\n",
        "        ]\n",
        "\n",
        "        # SORT: Matches (Desc) -> Total Frequency (Desc)\n",
        "        ranked_results.sort(key=lambda x: (x[1], x[2]), reverse=True)\n",
        "\n",
        "        return ranked_results[:num_results]\n",
        "\n",
        "print(\" Store classes + Inverted index classes defined\")"
      ],
      "metadata": {
        "id": "H6h6ichmcgHy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 4: Core setup (custom stopwords + stemming + embedding model + FAISS)\n",
        "\n",
        "# We remove these words because they are very frequent function words (articles, prepositions, pronouns).\n",
        "# They usually do not add topic meaning, but they increase index size and add noise to retrieval.\n",
        "CUSTOM_STOPWORDS = {\n",
        "    \"the\",\"a\",\"an\",\"and\",\"or\",\"but\",\n",
        "    \"to\",\"of\",\"in\",\"on\",\"at\",\"for\",\"from\",\"by\",\"with\",\"as\",\n",
        "    \"is\",\"are\",\"was\",\"were\",\"be\",\"been\",\"being\",\n",
        "    \"this\",\"that\",\"these\",\"those\",\n",
        "    \"it\",\"its\",\"they\",\"them\",\"their\",\"we\",\"our\",\"you\",\"your\",\n",
        "    \"i\",\"me\",\"my\",\"he\",\"him\",\"his\",\"she\",\"her\",\n",
        "    \"not\",\"no\",\"do\",\"does\",\"did\",\"doing\"\n",
        "}\n",
        "\n",
        "# Chops off word endings to find the \"root\" (stem)\n",
        "stemmer = PorterStemmer()\n",
        "\n",
        "def preprocess_text(text: str):\n",
        "    \"\"\"\n",
        "    Returns list of terms for indexing:\n",
        "    - lowercase\n",
        "    - tokenize\n",
        "    - keep alphabetic tokens only\n",
        "    - remove custom stopwords\n",
        "    - apply stemming\n",
        "    \"\"\"\n",
        "    text = text.lower()\n",
        "    tokens = word_tokenize(text)\n",
        "    terms = []\n",
        "    for tok in tokens:\n",
        "        if tok.isalpha() and tok not in CUSTOM_STOPWORDS:\n",
        "            terms.append(stemmer.stem(tok))\n",
        "    return terms\n",
        "\n",
        "# --- Embedding model (for semantic retrieval) ---\n",
        "embed_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# --- FAISS index (stores embeddings for doc-level retrieval) ---\n",
        "faiss_index = None\n",
        "vector_dim = None\n",
        "\n",
        "# Parallel stores (FAISS row -> doc data)\n",
        "vector_doc_ids = []   # doc_id\n",
        "vector_texts = []     # full doc text\n",
        "\n",
        "print(\" Core setup ready (custom stopwords + stemming + embeddings + FAISS)\")"
      ],
      "metadata": {
        "id": "eOcug8jcPQ7P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --- NEW CELL: GEMINI SETUP (Universal Fix) ---\n",
        "\n",
        "# Your encoded key\n",
        "encoded_str = \"CkFJemFTeUJ3TjVpV2tleUJsUmRmVl9YdlljM2ZQZHA5bERSOFJ5SQo=\"\n",
        "\n",
        "# 1. Decode\n",
        "decoded_bytes = base64.b64decode(encoded_str)\n",
        "\n",
        "# 2. Convert to string and STRIP whitespace/newlines\n",
        "MY_API_KEY = decoded_bytes.decode(\"utf-8\").strip()\n",
        "\n",
        "genai.configure(api_key=MY_API_KEY)\n",
        "\n",
        "# 1. DYNAMICALLY FIND A WORKING MODEL\n",
        "print(\"üîÑ Connecting to Google API to find valid models...\")\n",
        "valid_model_name = \"\"\n",
        "\n",
        "try:\n",
        "    for m in genai.list_models():\n",
        "        if 'generateContent' in m.supported_generation_methods:\n",
        "            # We prefer 1.5 Flash, but we will take ANYTHING that works\n",
        "            if \"flash\" in m.name:\n",
        "                valid_model_name = m.name\n",
        "                break # Found the best one, stop looking\n",
        "            elif \"gemini-pro\" in m.name and not valid_model_name:\n",
        "                valid_model_name = m.name\n",
        "\n",
        "    if not valid_model_name:\n",
        "        # Fallback if the loop found nothing\n",
        "        valid_model_name = \"models/gemini-pro\"\n",
        "\n",
        "    print(f\"‚úÖ FOUND VALID MODEL: {valid_model_name}\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error listing models: {e}\")\n",
        "    print(\"Defaulting to 'models/gemini-pro'\")\n",
        "    valid_model_name = \"models/gemini-pro\"\n",
        "\n",
        "\n",
        "def ask_gemini(context, user_question):\n",
        "    if not context: return \"No relevant info found.\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    Answer based ONLY on this context:\n",
        "    {context}\n",
        "\n",
        "    Question: {user_question}\n",
        "    \"\"\"\n",
        "\n",
        "    try:\n",
        "        # Use the variable we found earlier\n",
        "        model = genai.GenerativeModel(valid_model_name)\n",
        "        response = model.generate_content(prompt)\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"Error: {e}\"\n",
        "\n",
        "print(\"‚úÖ Setup Complete. Ready to run RAG.\")"
      ],
      "metadata": {
        "id": "zPjbOgTkMFZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 5: Wikipedia source links (seed documents for the corpus)\n",
        "\n",
        "wiki_links = [\n",
        "    \"https://en.wikipedia.org/wiki/Plant_disease\",\n",
        "    \"https://en.wikipedia.org/wiki/Plant_pathology\",\n",
        "    \"https://en.wikipedia.org/wiki/Fungus\",\n",
        "    \"https://en.wikipedia.org/wiki/Bacterial_wilt\",\n",
        "    \"https://en.wikipedia.org/wiki/Powdery_mildew\"\n",
        "]\n",
        "\n",
        "print(\"Wikipedia links used:\")\n",
        "for i, link in enumerate(wiki_links, 1):\n",
        "    print(f\"{i}. {link}\")\n"
      ],
      "metadata": {
        "id": "F5Swqy3GdK37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 6: Load documents from Wikipedia (API fetch + normalization + metadata)\n",
        "\n",
        "WIKI_API = \"https://en.wikipedia.org/w/api.php\"\n",
        "\n",
        "# Wikipedia blocks requests without a proper User-Agent sometimes\n",
        "HEADERS = {\n",
        "    \"User-Agent\": \"HW02-Cloud-RAG/1.0 (student project; contact: abrahem.sadekk@gmail.com)\"\n",
        "}\n",
        "\n",
        "# Extract the actual topic from a messy link\n",
        "def title_from_wiki_url(url: str) -> str:\n",
        "    if \"/wiki/\" not in url:\n",
        "        raise ValueError(f\"Unsupported Wikipedia URL: {url}\")\n",
        "    title = url.split(\"/wiki/\", 1)[1]\n",
        "    title = title.split(\"#\", 1)[0]      # remove anchors\n",
        "    title = title.replace(\"_\", \" \")\n",
        "    return title\n",
        "\n",
        "# This is the \"Worker Bee\" function. It talks to Wikipedia's servers\n",
        "def fetch_page_extract_by_title(title: str):\n",
        "    # This dictionary tells Wikipedia exactly what you want\n",
        "    params = {\n",
        "        \"action\": \"query\",\n",
        "        \"format\": \"json\",\n",
        "        \"prop\": \"extracts|info\",\n",
        "        \"titles\": title,\n",
        "        \"inprop\": \"url\",\n",
        "        \"explaintext\": True,\n",
        "        \"redirects\": 1,   # follow redirects\n",
        "        \"origin\": \"*\"     # helps in some environments\n",
        "    }\n",
        "    r = requests.get(WIKI_API, params=params, headers=HEADERS, timeout=30)\n",
        "    r.raise_for_status()\n",
        "\n",
        "    pages = r.json()[\"query\"][\"pages\"]\n",
        "    page = next(iter(pages.values()))\n",
        "\n",
        "    # Handle missing page\n",
        "    if \"missing\" in page:\n",
        "        return {\"pageid\": None, \"title\": title, \"url\": \"\", \"text\": \"\"}\n",
        "\n",
        "    return {\n",
        "        \"pageid\": page.get(\"pageid\"),\n",
        "        \"title\": page.get(\"title\", title),\n",
        "        \"url\": page.get(\"fullurl\", \"\"),\n",
        "        \"text\": page.get(\"extract\", \"\")\n",
        "    }\n",
        "\n",
        "def slugify(s: str) -> str:\n",
        "    s = s.strip().lower()\n",
        "    s = re.sub(r\"[^a-z0-9]+\", \"-\", s)\n",
        "    return s.strip(\"-\")\n",
        "\n",
        "def load_docs_from_wiki_links(wiki_links):\n",
        "    docs = {}\n",
        "    docs_meta = {}\n",
        "\n",
        "    for url in wiki_links:\n",
        "        title = title_from_wiki_url(url)\n",
        "        data = fetch_page_extract_by_title(title)\n",
        "\n",
        "        text = (data.get(\"text\") or \"\").strip()\n",
        "        if not text:\n",
        "            print(f\"Empty/blocked page: {title} | {url}\")\n",
        "            continue\n",
        "\n",
        "        doc_id = f\"wiki_{slugify(data['title'])}\"\n",
        "        docs[doc_id] = text\n",
        "        docs_meta[doc_id] = {\n",
        "            \"title\": data[\"title\"],\n",
        "            \"url\": data.get(\"url\") or url,\n",
        "            \"source\": \"wikipedia\",\n",
        "            \"pageid\": data.get(\"pageid\"),\n",
        "        }\n",
        "\n",
        "        print(f\"Loaded: {data['title']} -> {doc_id} | chars={len(text)}\")\n",
        "\n",
        "    return docs, docs_meta\n",
        "\n",
        "docs, docs_meta = load_docs_from_wiki_links(wiki_links)\n",
        "print(\"Docs loaded:\", len(docs))\n"
      ],
      "metadata": {
        "id": "ka2aEOAOgS2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 7: Firebase Initialization (Hybrid Safe Mode)\n",
        "\n",
        "# --- 1. Public Configuration (Safe to share) ---\n",
        "# We keep the standard info visible so the code is easy to understand.\n",
        "config = {\n",
        "  \"type\": \"service_account\",\n",
        "  \"project_id\": \"hw02-cloud-inverted-index\",\n",
        "  \"private_key_id\": \"437db7abaab45e69cf2bf0c22aa8c2e23cbbc71e\",\n",
        "  \"client_email\": \"firebase-adminsdk-fbsvc@hw02-cloud-inverted-index.iam.gserviceaccount.com\",\n",
        "  \"client_id\": \"105185385505390955098\",\n",
        "  \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n",
        "  \"token_uri\": \"https://oauth2.googleapis.com/token\",\n",
        "  \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n",
        "  \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/firebase-adminsdk-fbsvc%40hw02-cloud-inverted-index.iam.gserviceaccount.com\",\n",
        "  \"universe_domain\": \"googleapis.com\"\n",
        "}\n",
        "\n",
        "# --- 2. Private Key (Hidden) ---\n",
        "scrambled_key = \"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\"\n",
        "\n",
        "try:\n",
        "    # We unlock the key and add it to the config\n",
        "    config[\"private_key\"] = base64.b64decode(scrambled_key).decode('utf-8')\n",
        "\n",
        "    # Initialize Firebase\n",
        "    cred = credentials.Certificate(config)\n",
        "\n",
        "    if not firebase_admin._apps:\n",
        "        firebase_admin.initialize_app(cred)\n",
        "\n",
        "    db = firestore.client()\n",
        "    print(\"Firestore connected successfully to:\", db.project)\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"Error: {e}\")"
      ],
      "metadata": {
        "id": "z3PfU1boz_l-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 8: Build Index (Inverted Index + SMART CHUNKING)\n",
        "\n",
        "# ==========================================\n",
        "# PART 1: Build Inverted Index (Local Logic)\n",
        "# ==========================================\n",
        "# We always build this locally because it's fast and relies on the full text\n",
        "inv_index = InvertedIndexStore()\n",
        "print(\"Building Inverted Index...\")\n",
        "\n",
        "for doc_id, text in docs.items():\n",
        "    terms = preprocess_text(text)\n",
        "    term_counts = defaultdict(int)\n",
        "    for t in terms:\n",
        "        term_counts[t] += 1\n",
        "    for t, count in term_counts.items():\n",
        "        inv_index.add_occurrence(t, doc_id, count)\n",
        "\n",
        "print(f\" Inverted index built. Unique terms: {inv_index.count_terms()}\")\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# PART 2: Smart Chunking (Cloud Check)\n",
        "# ==========================================\n",
        "# Goal: Get chunks from Firebase if they exist; otherwise create & upload them.\n",
        "\n",
        "collection_name = \"chunks\"\n",
        "col = db.collection(collection_name)\n",
        "\n",
        "vector_doc_ids = []  # Maps row_id -> doc_id\n",
        "vector_texts = []    # Maps row_id -> chunk text\n",
        "\n",
        "# Check if we already have data in the cloud\n",
        "# We fetch just 1 document to check existence\n",
        "is_cloud_ready = len(list(col.limit(1).stream())) > 0\n",
        "\n",
        "if is_cloud_ready:\n",
        "    print(f\"‚òÅÔ∏è Found chunks in Firestore collection '{collection_name}'. Downloading...\")\n",
        "\n",
        "    # Download everything from chunks collection\n",
        "    # Note: For huge datasets, you would use pagination. For this homework, it's fine.\n",
        "    all_chunks = col.stream()\n",
        "\n",
        "    for doc in all_chunks:\n",
        "        data = doc.to_dict()\n",
        "        vector_texts.append(data['text'])\n",
        "        vector_doc_ids.append(data['doc_id'])\n",
        "\n",
        "    print(f\"‚úÖ Downloaded {len(vector_texts)} chunks from Cloud.\")\n",
        "\n",
        "else:\n",
        "    print(f\"‚ö†Ô∏è No chunks found in Cloud. Generating locally & Uploading...\")\n",
        "\n",
        "    # --- Local Chunking Logic ---\n",
        "    chunk_size = 500\n",
        "    overlap = 50\n",
        "\n",
        "    batch = db.batch()\n",
        "    ops = 0\n",
        "    chunk_counter = 0\n",
        "\n",
        "    for doc_id, text in docs.items():\n",
        "        # Sliding window split\n",
        "        for i in range(0, len(text), chunk_size - overlap):\n",
        "            chunk = text[i:i + chunk_size]\n",
        "            if len(chunk) < 30: continue\n",
        "\n",
        "            # Add to local lists (for FAISS)\n",
        "            vector_texts.append(chunk)\n",
        "            vector_doc_ids.append(doc_id)\n",
        "\n",
        "            # Add to Firestore Batch (for Persistence)\n",
        "            chunk_ref = col.document(f\"chunk_{chunk_counter}\")\n",
        "            batch.set(chunk_ref, {\n",
        "                \"chunk_id\": chunk_counter,\n",
        "                \"doc_id\": doc_id,\n",
        "                \"text\": chunk,\n",
        "                \"len\": len(chunk)\n",
        "            })\n",
        "\n",
        "            chunk_counter += 1\n",
        "            ops += 1\n",
        "\n",
        "            # Commit batch if full\n",
        "            if ops >= 400:\n",
        "                batch.commit()\n",
        "                print(f\"  Uploaded batch of 400 chunks...\")\n",
        "                batch = db.batch()\n",
        "                ops = 0\n",
        "\n",
        "    # Final commit\n",
        "    if ops > 0:\n",
        "        batch.commit()\n",
        "\n",
        "    print(f\"‚úÖ Generated & Uploaded {len(vector_texts)} chunks to Firestore.\")\n",
        "\n",
        "\n",
        "# ==========================================\n",
        "# PART 3: Build FAISS Index\n",
        "# ==========================================\n",
        "# Whether we got data from Cloud or Local, we now build the vector index\n",
        "print(\"Building FAISS index...\")\n",
        "\n",
        "emb = embed_model.encode(vector_texts, convert_to_numpy=True, normalize_embeddings=True).astype(\"float32\")\n",
        "\n",
        "vector_dim = emb.shape[1]\n",
        "faiss_index = faiss.IndexFlatIP(vector_dim)\n",
        "faiss_index.add(emb)\n",
        "\n",
        "print(f\"‚úÖ FAISS built. Total Vectors: {faiss_index.ntotal}\")"
      ],
      "metadata": {
        "id": "x1SNUhlfQPfG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 9: Upload inverted index to Firestore (Safe Mode)\n",
        "\n",
        "def upload_inverted_index(inv_index, db_client, collection_name=\"inverted_index\", batch_size=400):\n",
        "    \"\"\"\n",
        "    Uploads the inverted index to Firestore.\n",
        "    SAFE MODE: Checks if collection is not empty before uploading.\n",
        "    \"\"\"\n",
        "    col = db_client.collection(collection_name)\n",
        "\n",
        "    # --- SAFETY CHECK ---\n",
        "    # We try to get just 1 document to see if the collection exists\n",
        "    existing_docs = list(col.limit(1).stream())\n",
        "    if len(existing_docs) > 0:\n",
        "        print(f\"‚ö†Ô∏è Collection '{collection_name}' already contains data. Skipping upload to prevent overwrite.\")\n",
        "        return\n",
        "    # --------------------\n",
        "\n",
        "    # Ensure your inv_index object has this method.\n",
        "    records = inv_index.to_required_format()\n",
        "\n",
        "    batch = db_client.batch()\n",
        "    ops = 0\n",
        "\n",
        "    print(f\"Starting upload of {len(records)} terms...\")\n",
        "\n",
        "    for r in records:\n",
        "        term = r[\"term\"]\n",
        "        doc_ids = r[\"DocIDs\"]\n",
        "\n",
        "        # Sanitize ID: Firestore IDs cannot contain '/'\n",
        "        safe_term = term.replace(\"/\", \"_\")\n",
        "        # Limit length to 1500 bytes (Firestore limit per ID)\n",
        "        doc_id = safe_term[:1500]\n",
        "\n",
        "        ref = col.document(doc_id)\n",
        "\n",
        "        # We use .set() here because we already confirmed the collection was empty.\n",
        "        batch.set(ref, {\n",
        "            \"term\": term,         # Store original term inside the document\n",
        "            \"doc_ids\": doc_ids,\n",
        "            \"df\": len(doc_ids),\n",
        "        })\n",
        "\n",
        "        ops += 1\n",
        "        if ops >= batch_size:\n",
        "            batch.commit()\n",
        "            print(f\"  committed batch of {batch_size}...\")\n",
        "            batch = db_client.batch()\n",
        "            ops = 0\n",
        "\n",
        "    if ops > 0:\n",
        "        batch.commit()\n",
        "\n",
        "    print(f\"‚úÖ Uploaded {len(records)} terms to Firestore collection '{collection_name}'\")\n",
        "\n",
        "# Execute the upload passing the 'db' from Cell 8\n",
        "upload_inverted_index(inv_index, db)"
      ],
      "metadata": {
        "id": "3GMKBFBw1sdE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 10: Upload Wikipedia document metadata to Firestore (documents collection)\n",
        "\n",
        "def upload_wiki_meta(docs_meta, collection_name=\"documents\", batch_size=400):\n",
        "    \"\"\"\n",
        "    Uploads Wikipedia document metadata to Firestore.\n",
        "\n",
        "    Each document is stored as:\n",
        "      documents/{doc_id}\n",
        "\n",
        "    Stored fields:\n",
        "      - doc_id  : your internal document ID (e.g., wiki_plant-disease)\n",
        "      - title   : Wikipedia page title\n",
        "      - url     : Wikipedia page URL\n",
        "      - source  : \"wikipedia\"\n",
        "      - pageid  : Wikipedia page id (if available)\n",
        "\n",
        "    This does NOT upload the full article text; it only uploads metadata.\n",
        "    \"\"\"\n",
        "    col = db.collection(collection_name)\n",
        "\n",
        "    batch = db.batch()\n",
        "    ops = 0\n",
        "\n",
        "    for doc_id, meta in docs_meta.items():\n",
        "        ref = col.document(doc_id)\n",
        "        batch.set(ref, {\n",
        "            \"doc_id\": doc_id,\n",
        "            \"title\": meta.get(\"title\", \"\"),\n",
        "            \"url\": meta.get(\"url\", \"\"),\n",
        "            \"source\": meta.get(\"source\", \"wikipedia\"),\n",
        "            \"pageid\": meta.get(\"pageid\", None),\n",
        "        }, merge=True)\n",
        "\n",
        "        ops += 1\n",
        "        if ops >= batch_size:\n",
        "            batch.commit()\n",
        "            batch = db.batch()\n",
        "            ops = 0\n",
        "\n",
        "    if ops > 0:\n",
        "        batch.commit()\n",
        "\n",
        "    print(f\"Uploaded {len(docs_meta)} wiki docs to '{collection_name}'\")\n",
        "\n",
        "# Upload metadata for the loaded Wikipedia docs\n",
        "upload_wiki_meta(docs_meta)\n"
      ],
      "metadata": {
        "id": "Al003f-n5Ubq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 11: Retrieval (Chunk-Aware)\n",
        "\n",
        "def retrieve_top_docs(query: str, top_k: int = 5):\n",
        "    \"\"\"\n",
        "    Retrieves the most relevant CHUNKS (paragraphs) from the database.\n",
        "    \"\"\"\n",
        "    if faiss_index is None or faiss_index.ntotal == 0:\n",
        "        return \"FAISS index is empty. Build vectors first.\"\n",
        "\n",
        "    # Embed query\n",
        "    q_emb = embed_model.encode(\n",
        "        [query],\n",
        "        convert_to_numpy=True,\n",
        "        normalize_embeddings=True\n",
        "    ).astype(\"float32\")\n",
        "\n",
        "    # Search FAISS\n",
        "    distances, indices = faiss_index.search(q_emb, top_k)\n",
        "\n",
        "    lines = []\n",
        "    lines.append(f\"Query: '{query}'\")\n",
        "    lines.append(\"Context found in Knowledge Base:\")\n",
        "    lines.append(\"=\" * 60)\n",
        "\n",
        "    for rank, idx in enumerate(indices[0], start=1):\n",
        "        if idx == -1: continue\n",
        "\n",
        "        # The 'idx' now points to a CHUNK, not a full document\n",
        "        doc_id = vector_doc_ids[idx]\n",
        "        chunk_text = vector_texts[idx]\n",
        "\n",
        "        # Get metadata\n",
        "        meta = docs_meta.get(doc_id, {})\n",
        "        title = meta.get(\"title\", doc_id)\n",
        "        score = float(distances[0][rank - 1])\n",
        "\n",
        "        lines.append(f\"--- Result {rank} (Source: {title} | Score: {score:.4f}) ---\")\n",
        "        lines.append(chunk_text) # This is the specific 500-char chunk\n",
        "        lines.append(\"\\n\")\n",
        "\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "print(\"‚úÖ Retrieval function updated (Chunk-Aware)\")"
      ],
      "metadata": {
        "id": "ZdcfV4LzBs79"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 12: RAG-style output (retrieval + \"enriched\" answer without OpenAI)\n",
        "# We will: retrieve top docs, then produce a simple enriched response by extracting key sentences.\n",
        "\n",
        "def split_sentences(text: str):\n",
        "    # simple sentence split (good enough for baseline)\n",
        "    parts = re.split(r'(?<=[.!?])\\s+', re.sub(r\"\\s+\", \" \", text).strip())\n",
        "    return [s for s in parts if len(s) > 30]\n",
        "\n",
        "def rag_answer_without_llm(query: str, top_k: int = 3, max_sentences_per_doc: int = 2):\n",
        "    if faiss_index is None or faiss_index.ntotal == 0:\n",
        "        return \"FAISS index is empty. Build vectors first.\"\n",
        "\n",
        "    q_emb = embed_model.encode([query], convert_to_numpy=True, normalize_embeddings=True).astype(\"float32\")\n",
        "    distances, indices = faiss_index.search(q_emb, top_k)\n",
        "\n",
        "    lines = []\n",
        "    lines.append(f\"Query: {query}\")\n",
        "    lines.append(\"=\" * 60)\n",
        "\n",
        "    # Retrieval section\n",
        "    lines.append(\"Top retrieved documents:\")\n",
        "    retrieved = []\n",
        "    for rank, idx in enumerate(indices[0], start=1):\n",
        "        if idx == -1:\n",
        "            continue\n",
        "        doc_id = vector_doc_ids[idx]\n",
        "        title = docs_meta.get(doc_id, {}).get(\"title\", \"\")\n",
        "        score = float(distances[0][rank - 1])\n",
        "        retrieved.append((doc_id, title, score))\n",
        "        lines.append(f\"{rank}) {doc_id} | {title} | similarity: {score:.4f}\")\n",
        "    lines.append(\"=\" * 60)\n",
        "\n",
        "    # Enriched response (extractive, no LLM)\n",
        "    lines.append(\"Enriched response (extractive, no LLM):\")\n",
        "    q_terms = set(preprocess_text(query))\n",
        "\n",
        "    for doc_id, title, score in retrieved:\n",
        "        text = docs[doc_id]\n",
        "        sents = split_sentences(text)\n",
        "\n",
        "        # score sentences by overlap with query terms (stems)\n",
        "        scored = []\n",
        "        for s in sents:\n",
        "            s_terms = set(preprocess_text(s))\n",
        "            overlap = len(q_terms & s_terms)\n",
        "            if overlap > 0:\n",
        "                scored.append((overlap, s))\n",
        "\n",
        "        scored.sort(key=lambda x: x[0], reverse=True)\n",
        "        best = [s for _, s in scored[:max_sentences_per_doc]]\n",
        "\n",
        "        lines.append(f\"- Source: {doc_id} | {title}\")\n",
        "        if best:\n",
        "            for b in best:\n",
        "                lines.append(f\"  ‚Ä¢ {b}\")\n",
        "        else:\n",
        "            lines.append(\"  ‚Ä¢ (No strong matching sentences found)\")\n",
        "        lines.append(\"-\" * 60)\n",
        "\n",
        "    return \"\\n\".join(lines)\n",
        "\n",
        "print(\" RAG-style (no OpenAI) function ready\")\n"
      ],
      "metadata": {
        "id": "yNqRTEkVPTuC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 13: RAG Logic Wrapper\n",
        "\n",
        "def get_rag_response(query: str):\n",
        "    \"\"\"\n",
        "    Core RAG logic: Retrieves docs and generates an answer.\n",
        "    Call this function from your GUI (Screen E) or any other interface.\n",
        "    \"\"\"\n",
        "    # 1. Retrieve top docs (using the function from previous cells)\n",
        "    context = retrieve_top_docs(query, top_k=3)\n",
        "\n",
        "    # 2. Safety check: Ensure the index isn't empty\n",
        "    if \"FAISS index is empty\" in context:\n",
        "        return \"‚ö†Ô∏è Error: Index is empty. Please run the vector build cell first.\"\n",
        "\n",
        "    # 3. Generate Answer using Gemini\n",
        "    return ask_gemini(context, query)\n",
        "\n",
        "print(\"‚úÖ RAG Logic ready. Use 'get_rag_response(query)' to get answers.\")"
      ],
      "metadata": {
        "id": "vwNeEQGa9Mw8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##CHATBOT Gemini"
      ],
      "metadata": {
        "id": "jpGcLICllG41"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 01: Define \"Patterns\" (System Instructions)\n",
        "\n",
        "# We tell Gemini how to behave to mimic the NLTK patterns\n",
        "system_instruction = \"\"\"\n",
        "You are a helpful chatbot.\n",
        "- If user says 'hi' or 'hello', answer: 'Hello there!'\n",
        "- If user asks 'what is your name', answer: 'I am a Gemini Chatbot.'\n",
        "- If user asks 'how are you', answer: 'I am doing well, thank you!'\n",
        "- Otherwise, answer helpfully and concisely.\n",
        "\"\"\"\n",
        "\n",
        "print(\"‚úÖ CELL 01: Patterns defined.\")"
      ],
      "metadata": {
        "id": "t_ggrDW5lJSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 02: Build the Chatbot\n",
        "\n",
        "# We use the 'valid_model_name' from your existing setup code\n",
        "model = genai.GenerativeModel(\n",
        "    valid_model_name,\n",
        "    system_instruction=system_instruction\n",
        ")\n",
        "\n",
        "# Start the chat session (equivalent to initializing NLTK Chat)\n",
        "chat_session = model.start_chat(history=[])\n",
        "\n",
        "print(f\"‚úÖ CELL 02: Chatbot built using {valid_model_name}.\")"
      ],
      "metadata": {
        "id": "kL6voX75lKJU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#FROM NOW ON. ASAAD'S PART"
      ],
      "metadata": {
        "id": "ZJL2UYRadFR_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 001: Firebase Initialization\n",
        "import firebase_admin\n",
        "from firebase_admin import credentials, firestore\n",
        "from google.colab import userdata\n",
        "import json\n",
        "import requests\n",
        "import pandas as pd\n",
        "\n",
        "# Check if Firebase is already running to avoid re-initialization error\n",
        "if not firebase_admin._apps:\n",
        "    try:\n",
        "        # Use Colab Secrets instead of a file path\n",
        "        key_content = userdata.get('FIREBASE_KEY')\n",
        "        key_dict = json.loads(key_content)\n",
        "        cred = credentials.Certificate(key_dict)\n",
        "        firebase_admin.initialize_app(cred)\n",
        "        print(\"‚úÖ Firebase app initialized using Colab secrets.\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error initializing Firebase: {e}\")\n",
        "\n",
        "# Get the client (works even if initialized in previous cells)\n",
        "try:\n",
        "    db = firestore.client()\n",
        "    print(\"‚úÖ Connected to Firestore in project:\", db.project)\n",
        "except:\n",
        "    db = None\n",
        "    print(\"‚ö†Ô∏è DB not connected.\")"
      ],
      "metadata": {
        "id": "DmIJXYU1dIqi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 002: IoT Fetcher\n",
        "BASE_URL = \"https://server-cloud-v645.onrender.com\"\n",
        "\n",
        "def fetch_history(feed: str, limit: int = 30) -> pd.DataFrame:\n",
        "    \"\"\"Fetch IoT history from course server. Returns DataFrame with created_at,value.\"\"\"\n",
        "    try:\n",
        "        resp = requests.get(f\"{BASE_URL}/history\", params={\"feed\": feed, \"limit\": int(limit)}, timeout=10)\n",
        "        resp.raise_for_status()\n",
        "        data = resp.json()\n",
        "        if \"data\" not in data: return pd.DataFrame()\n",
        "\n",
        "        df = pd.DataFrame(data[\"data\"])\n",
        "        df[\"created_at\"] = pd.to_datetime(df[\"created_at\"], errors=\"coerce\")\n",
        "        df[\"value\"] = pd.to_numeric(df[\"value\"], errors=\"coerce\")\n",
        "        df = df.dropna(subset=[\"created_at\", \"value\"]).sort_values(\"created_at\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"Error fetching IoT: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "print(\"‚úÖ IoT Fetcher ready.\")"
      ],
      "metadata": {
        "id": "WfyJ7ggJnUBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "13ae3534"
      },
      "source": [
        "# CELL 003-A: UI Helper Functions (REQUIRED)\n",
        "import ipywidgets as widgets\n",
        "from IPython.display import display, clear_output\n",
        "\n",
        "def create_card(title, subtitle, content_list):\n",
        "    \"\"\"Creates a visible card-like container for the UI.\"\"\"\n",
        "    header = widgets.HTML(f\"\"\"\n",
        "    <div style=\"margin-bottom: 10px;\">\n",
        "        <h3 style=\"margin: 0; color: #333;\">{title}</h3>\n",
        "        <span style=\"font-size: 12px; color: #777;\">{subtitle}</span>\n",
        "    </div>\n",
        "    <hr style=\"border: 0; border-top: 1px solid #eee; margin: 10px 0;\">\n",
        "    \"\"\")\n",
        "    card_items = [header] + content_list\n",
        "    card = widgets.VBox(\n",
        "        card_items,\n",
        "        layout=widgets.Layout(\n",
        "            width='98%', border='1px solid #ddd', padding='15px',\n",
        "            margin='10px 0', border_radius='8px', background_color='#fafafa'\n",
        "        )\n",
        "    )\n",
        "    return card\n",
        "\n",
        "print(\"‚úÖ UI Helpers defined.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e7f4f7c7"
      },
      "source": [
        "# CELL 003: Gamification Logic\n",
        "gamification_user_id = 'colab-user-123'\n",
        "gamification_state = {}\n",
        "gamif_ui_bars = []\n",
        "\n",
        "XP_LEVELS = {1: 0, 2: 100, 3: 250, 4: 500, 5: 1000, 6: 1750, 7: 2750, 8: 4000, 9: 5500, 10: 7500}\n",
        "\n",
        "def load_gamification():\n",
        "    global gamification_state\n",
        "    try:\n",
        "        if db is None:\n",
        "            gamification_state = {'xp': 0, 'level': 1}\n",
        "            return\n",
        "        doc = db.collection('gamification').document(gamification_user_id).get()\n",
        "        if doc.exists:\n",
        "            data = doc.to_dict()\n",
        "            gamification_state['xp'] = data.get('xp', 0)\n",
        "            gamification_state['level'] = data.get('level', 1)\n",
        "            print(\"‚úÖ Gamification loaded.\")\n",
        "        else:\n",
        "            gamification_state = {'xp': 0, 'level': 1}\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading gamification: {e}\")\n",
        "        gamification_state = {'xp': 0, 'level': 1}\n",
        "\n",
        "def save_gamification(state):\n",
        "    if db: db.collection('gamification').document(gamification_user_id).set(state)\n",
        "\n",
        "def refresh_gamif_ui():\n",
        "    # (Simple refresh logic)\n",
        "    current_xp = gamification_state.get('xp', 0)\n",
        "    current_level = gamification_state.get('level', 1)\n",
        "    bar_html = f\"<div style='background:#ddd; height:5px;'><div style='width:50%; background:green; height:5px;'></div></div> Lvl {current_level}\"\n",
        "    for ui_bar in gamif_ui_bars:\n",
        "        ui_bar.value = bar_html\n",
        "\n",
        "def award_xp(amount):\n",
        "    global gamification_state\n",
        "    gamification_state['xp'] = gamification_state.get('xp', 0) + amount\n",
        "    # Check level (simplified for brevity)\n",
        "    if gamification_state['xp'] > 100 * gamification_state.get('level', 1):\n",
        "        gamification_state['level'] += 1\n",
        "    save_gamification(gamification_state)\n",
        "    refresh_gamif_ui()\n",
        "\n",
        "load_gamification()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "559467a1"
      },
      "source": [
        "# CELL 004: Leaderboard Screen\n",
        "import random\n",
        "lb_out = widgets.Output()\n",
        "lb_btn = widgets.Button(description=\"Refresh Leaderboard\", layout=widgets.Layout(width='auto', height='48px'))\n",
        "lb_btn.add_class(\"btn-primary\")\n",
        "\n",
        "def render_leaderboard(_=None):\n",
        "    with lb_out:\n",
        "        clear_output(wait=True)\n",
        "        my_xp = gamification_state.get('xp', 0)\n",
        "        # Fake users\n",
        "        fake_users = [{\"name\": \"Leaf_Ninja\", \"xp\": 1200}, {\"name\": \"You\", \"xp\": my_xp}]\n",
        "        df = pd.DataFrame(fake_users).sort_values(by='xp', ascending=False)\n",
        "        display(widgets.HTML(df.to_html(index=False)))\n",
        "\n",
        "lb_btn.on_click(render_leaderboard)\n",
        "\n",
        "# Creates 'screenG' variable needed by the final cell\n",
        "screenG = create_card(\"Leaderboard\", \"Top levels in PlantCare AI (demo)\", [lb_btn, lb_out])\n",
        "print(\"‚úÖ Leaderboard screen created.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# CELL 005: Update Leaderboard\n",
        "gamif_ui_G = widgets.HTML()\n",
        "gamif_ui_bars.append(gamif_ui_G)\n",
        "screenG.children = (gamif_ui_G,) + screenG.children\n",
        "render_leaderboard()\n",
        "print(\"‚úÖ Gamification UI attached to Leaderboard.\")"
      ],
      "metadata": {
        "id": "dfArtKw9QAUZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6843c90a"
      },
      "source": [
        "# CELL 006: Main App Assembly (Updated with Smart Saving)\n",
        "\n",
        "import pandas as pd\n",
        "import ipywidgets as widgets\n",
        "from transformers import pipeline\n",
        "import requests\n",
        "import io\n",
        "from PIL import Image\n",
        "from datetime import datetime, timezone\n",
        "import time # Added for the throttling logic\n",
        "\n",
        "# Global variable to track the last time we saved to Firebase\n",
        "# We set it to 0 so it saves immediately on the very first click\n",
        "last_iot_save_time = 0\n",
        "\n",
        "BASE_URL = \"https://server-cloud-v645.onrender.com\"\n",
        "\n",
        "def fetch_history(feed: str, limit: int = 30) -> pd.DataFrame:\n",
        "    \"\"\"Fetch IoT history from course server. Returns DataFrame with created_at,value.\"\"\"\n",
        "    try:\n",
        "        resp = requests.get(f\"{BASE_URL}/history\", params={\"feed\": feed, \"limit\": int(limit)}, timeout=120)\n",
        "        resp.raise_for_status()\n",
        "        data = resp.json()\n",
        "        if \"data\" not in data:\n",
        "            raise ValueError(f\"Server error: {data}\")\n",
        "\n",
        "        df = pd.DataFrame(data[\"data\"])\n",
        "        df[\"created_at\"] = pd.to_datetime(df[\"created_at\"], errors=\"coerce\")\n",
        "        df[\"value\"] = pd.to_numeric(df[\"value\"], errors=\"coerce\")\n",
        "        df = df.dropna(subset=[\"created_at\", \"value\"]).sort_values(\"created_at\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        print(f\"Fetch error: {e}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 1. MODEL SETUP\n",
        "# ---------------------------------------------------------------------\n",
        "MODEL_ID = \"linkanjarad/mobilenet_v2_1.0_224-plant-disease-identification\"\n",
        "# load hugging face model here\n",
        "print(\"‚è≥ Loading AI Model...\")\n",
        "clf = pipeline(\"image-classification\", model=MODEL_ID)\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# 2. DESIGN CSS (Bigger Stats, Side-by-Side Tables)\n",
        "# ---------------------------------------------------------------------\n",
        "CSS = \"\"\"\n",
        "<style>\n",
        "@import url('https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap');\n",
        "\n",
        ":root {\n",
        "    --bg-app: #f8fafc;\n",
        "    --surface: #ffffff;\n",
        "    --primary: #4f46e5;       /* Indigo */\n",
        "    --primary-hover: #4338ca;\n",
        "    --text-main: #0f172a;\n",
        "    --text-sub: #64748b;\n",
        "    --border: #e2e8f0;\n",
        "    --radius-l: 24px;\n",
        "    --radius-m: 16px;\n",
        "    --radius-s: 12px;\n",
        "    --shadow-card: 0 4px 6px -1px rgba(0, 0, 0, 0.05), 0 2px 4px -1px rgba(0, 0, 0, 0.03);\n",
        "}\n",
        "\n",
        ".jupyter-widgets, .widget-area {\n",
        "    font-family: 'Inter', system-ui, sans-serif !important;\n",
        "    color: var(--text-main);\n",
        "}\n",
        "\n",
        "/* App Wrapper */\n",
        ".app-shell {\n",
        "    background: var(--bg-app);\n",
        "    padding: 24px;\n",
        "    border-radius: 0 0 var(--radius-l) var(--radius-l);\n",
        "    border: 1px solid var(--border);\n",
        "}\n",
        "\n",
        "/* Modern Card */\n",
        ".gemini-card {\n",
        "    background: var(--surface);\n",
        "    border-radius: var(--radius-l);\n",
        "    padding: 32px;\n",
        "    border: 1px solid var(--border);\n",
        "    box-shadow: var(--shadow-card);\n",
        "    margin-bottom: 24px;\n",
        "}\n",
        ".gemini-card h2 {\n",
        "    color: var(--text-main);\n",
        "    margin: 0 0 8px 0;\n",
        "    font-size: 22px;\n",
        "    font-weight: 700;\n",
        "}\n",
        ".gemini-card p {\n",
        "    color: var(--text-sub);\n",
        "    font-size: 14px;\n",
        "    margin: 0 0 24px 0;\n",
        "}\n",
        "\n",
        "/* Tabs */\n",
        ".p-TabBar-tab {\n",
        "    background: transparent !important;\n",
        "    border: none !important;\n",
        "    color: var(--text-sub) !important;\n",
        "    font-weight: 600 !important;\n",
        "    padding: 12px 24px !important;\n",
        "    border-radius: var(--radius-s) !important;\n",
        "    margin-right: 4px !important;\n",
        "    transition: all 0.2s;\n",
        "}\n",
        ".p-TabBar-tab:hover {\n",
        "    background: #f1f5f9 !important;\n",
        "    color: var(--text-main) !important;\n",
        "}\n",
        ".p-TabBar-tab.p-mod-current {\n",
        "    color: var(--primary) !important;\n",
        "    background: #eef2ff !important;\n",
        "}\n",
        "\n",
        "/* Inputs */\n",
        ".widget-text input,\n",
        ".widget-textarea textarea,\n",
        ".widget-dropdown select,\n",
        ".widget-readout {\n",
        "    background: #ffffff !important;\n",
        "    color: var(--text-main) !important;\n",
        "    border: 1px solid #cbd5e1 !important;\n",
        "    border-radius: var(--radius-s) !important;\n",
        "    padding: 12px !important;\n",
        "    font-size: 14px !important;\n",
        "    transition: all 0.2s;\n",
        "}\n",
        ".widget-text input:focus,\n",
        ".widget-textarea textarea:focus {\n",
        "    border-color: var(--primary) !important;\n",
        "    box-shadow: 0 0 0 3px rgba(79, 70, 229, 0.15) !important;\n",
        "}\n",
        "\n",
        "/* Buttons */\n",
        ".btn-primary button {\n",
        "    background: var(--primary) !important;\n",
        "    color: white !important;\n",
        "    border-radius: 50px !important;\n",
        "    font-weight: 600 !important;\n",
        "    border: none !important;\n",
        "    padding: 10px 24px !important;\n",
        "}\n",
        ".btn-warning button {\n",
        "    background: #f59e0b !important;\n",
        "    color: white !important;\n",
        "    border-radius: 50px !important;\n",
        "    font-weight: 600 !important;\n",
        "    border: none !important;\n",
        "}\n",
        "\n",
        "/* Chat Window Container */\n",
        ".chat-window {\n",
        "    background: #ffffff;\n",
        "    border: 1px solid var(--border);\n",
        "    border-radius: var(--radius-m);\n",
        "    padding: 20px;\n",
        "    background-image: radial-gradient(#f1f5f9 1px, transparent 1px);\n",
        "    background-size: 20px 20px;\n",
        "    height: 400px;\n",
        "    overflow-y: auto;\n",
        "}\n",
        "\n",
        "/* BIGGER STAT BOXES */\n",
        ".stat-box {\n",
        "    background: #f8fafc;\n",
        "    border: 1px solid #e2e8f0;\n",
        "    padding: 25px; /* Increased padding */\n",
        "    border-radius: 16px;\n",
        "    text-align: center;\n",
        "    flex: 1;\n",
        "    box-shadow: 0 2px 4px rgba(0,0,0,0.02);\n",
        "}\n",
        ".stat-title {\n",
        "    font-size: 14px;\n",
        "    color: #64748b;\n",
        "    font-weight: 700;\n",
        "    text-transform: uppercase;\n",
        "    letter-spacing: 0.5px;\n",
        "}\n",
        ".stat-val {\n",
        "    font-size: 32px; /* Bigger font */\n",
        "    font-weight: 800;\n",
        "    color: #0f172a;\n",
        "    margin: 10px 0;\n",
        "}\n",
        "\n",
        "/* Upload Widget */\n",
        ".widget-upload > label {\n",
        "    width: 100%;\n",
        "    border: 2px dashed #cbd5e1;\n",
        "    border-radius: var(--radius-m);\n",
        "    background: #f8fafc;\n",
        "    padding: 32px;\n",
        "    text-align: center;\n",
        "    cursor: pointer;\n",
        "    font-weight: 600;\n",
        "    color: var(--primary);\n",
        "}\n",
        "\n",
        "/* Side by Side Tables container */\n",
        ".tables-container {\n",
        "    display: flex;\n",
        "    gap: 15px;\n",
        "    width: 100%;\n",
        "    overflow-x: auto;\n",
        "}\n",
        "</style>\n",
        "\"\"\"\n",
        "display(widgets.HTML(CSS))\n",
        "\n",
        "def create_card(title, subtitle, children):\n",
        "    header = widgets.HTML(f\"<h2>{title}</h2><p>{subtitle}</p>\")\n",
        "    box = widgets.VBox([header] + children)\n",
        "    box.add_class(\"gemini-card\")\n",
        "    return box\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# SCREEN A ‚Äî PLANT DIAGNOSTIC\n",
        "# ---------------------------------------------------------------------\n",
        "a_out = widgets.Output()\n",
        "\n",
        "a_name = widgets.Text(\n",
        "    placeholder=\"Plant species (e.g. Tomato)\",\n",
        "    description=\"Name:\",\n",
        "    style={'description_width': '60px'},\n",
        "    layout=widgets.Layout(width='100%')\n",
        ")\n",
        "a_uploader = widgets.FileUpload(\n",
        "    accept=\"image/*\",\n",
        "    multiple=False,\n",
        "    description=\"üìÇ Upload Leaf Photo\"\n",
        ")\n",
        "a_uploader.layout = widgets.Layout(width='100%')\n",
        "a_btn = widgets.Button(description=\"Analyze & Save\", layout=widgets.Layout(width='100%', height='48px'))\n",
        "a_btn.add_class(\"btn-primary\")\n",
        "\n",
        "def on_plant_upload(change):\n",
        "    with a_out:\n",
        "        clear_output()\n",
        "        if not a_uploader.value: return\n",
        "        fname, f = list(a_uploader.value.items())[0]\n",
        "        display(widgets.Image(value=f[\"content\"], width=320, layout=widgets.Layout(border='4px solid #f1f5f9', border_radius='12px')))\n",
        "\n",
        "a_uploader.observe(on_plant_upload, names=\"value\")\n",
        "\n",
        "def run_plant_analysis(_):\n",
        "    with a_out:\n",
        "        clear_output()\n",
        "        if not a_uploader.value: return\n",
        "        fname, f = list(a_uploader.value.items())[0]\n",
        "        img = Image.open(io.BytesIO(f[\"content\"])).convert(\"RGB\")\n",
        "        preds = clf(img)\n",
        "        top = preds[0]\n",
        "        clear_output()\n",
        "        display(widgets.Image(value=f[\"content\"], width=320, layout=widgets.Layout(border_radius='12px')))\n",
        "\n",
        "        healthy = \"healthy\" in top[\"label\"].lower()\n",
        "        bg = \"#ecfdf5\" if healthy else \"#fef2f2\"\n",
        "        border = \"#10b981\" if healthy else \"#ef4444\"\n",
        "        text_col = \"#047857\" if healthy else \"#b91c1c\"\n",
        "\n",
        "        display(widgets.HTML(f\"\"\"\n",
        "            <div style=\"background:{bg}; color:{text_col}; padding:24px; border-radius:16px; margin-top:20px; border: 1px solid {border}; text-align:center;\">\n",
        "                <h3 style=\"margin:0;\">{top['label'].replace('_',' ').title()}</h3>\n",
        "                <p>Confidence: {top['score']*100:.2f}%</p>\n",
        "            </div>\n",
        "        \"\"\"))\n",
        "        try:\n",
        "            db.collection(\"plant_images\").add({ \"plant\": a_name.value, \"file\": fname, \"prediction\": top[\"label\"], \"score\": float(top[\"score\"]), \"time\": datetime.now(timezone.utc) })\n",
        "            award_xp(10) # Award XP after successful prediction and database save\n",
        "        except: pass\n",
        "\n",
        "a_btn.on_click(run_plant_analysis)\n",
        "screenA = create_card(\"Plant Diagnostic\", \"Identify plant diseases using AI.\", [a_name, widgets.HTML(\"<div style='height:15px'></div>\"), a_uploader, widgets.HTML(\"<div style='height:20px'></div>\"), a_btn, a_out])\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# SCREEN B ‚Äî IOT DATA (WITH 10-MINUTE SMART SAVING)\n",
        "# ---------------------------------------------------------------------\n",
        "b_out = widgets.Output()\n",
        "\n",
        "b_limit = widgets.IntSlider(\n",
        "    value=5, min=1, max=20, step=1,\n",
        "    description=\"Rows:\",\n",
        "    style={'description_width': '60px'},\n",
        "    layout=widgets.Layout(width='60%')\n",
        ")\n",
        "b_btn = widgets.Button(\n",
        "    description=\"Fetch Data\",\n",
        "    layout=widgets.Layout(width='50%', height='48px')\n",
        ")\n",
        "b_btn.add_class(\"btn-primary\")\n",
        "\n",
        "def fetch_sensor_data(_):\n",
        "    global last_iot_save_time\n",
        "\n",
        "    with b_out:\n",
        "        clear_output()\n",
        "        try:\n",
        "            # 1. Fetch all 3\n",
        "            df_soil = fetch_history(\"soil\", b_limit.value)\n",
        "            df_hum = fetch_history(\"humidity\", b_limit.value)\n",
        "            df_temp = fetch_history(\"temperature\", b_limit.value)\n",
        "\n",
        "            # 2. Get latest values safely\n",
        "            l_soil = float(df_soil[\"value\"].iloc[-1]) if not df_soil.empty else 0.0\n",
        "            l_hum = float(df_hum[\"value\"].iloc[-1]) if not df_hum.empty else 0.0\n",
        "            l_temp = float(df_temp[\"value\"].iloc[-1]) if not df_temp.empty else 0.0\n",
        "\n",
        "            # 3. BIGGER STAT CARDS\n",
        "            display(widgets.HTML(f\"\"\"\n",
        "            <div style=\"display:flex; gap:20px; margin-bottom:30px;\">\n",
        "                <div class=\"stat-box\">\n",
        "                    <div class=\"stat-title\">üå± Soil Moisture</div>\n",
        "                    <div class=\"stat-val\">{l_soil}%</div>\n",
        "                </div>\n",
        "                <div class=\"stat-box\">\n",
        "                    <div class=\"stat-title\">üíß Humidity</div>\n",
        "                    <div class=\"stat-val\">{l_hum}%</div>\n",
        "                </div>\n",
        "                <div class=\"stat-box\">\n",
        "                    <div class=\"stat-title\">üå°Ô∏è Temperature</div>\n",
        "                    <div class=\"stat-val\">{l_temp}¬∞C</div>\n",
        "                </div>\n",
        "            </div>\n",
        "            \"\"\"))\n",
        "\n",
        "            # 4. SIDE BY SIDE TABLES (Using HBox of Outputs)\n",
        "            out1 = widgets.Output()\n",
        "            out2 = widgets.Output()\n",
        "            out3 = widgets.Output()\n",
        "\n",
        "            with out1:\n",
        "                print(\"--- Soil ---\")\n",
        "                display(df_soil)\n",
        "            with out2:\n",
        "                print(\"--- Humidity ---\")\n",
        "                display(df_hum)\n",
        "            with out3:\n",
        "                print(\"--- Temp ---\")\n",
        "                display(df_temp)\n",
        "\n",
        "            # Put them in an HBox\n",
        "            hbox = widgets.HBox([out1, out2, out3])\n",
        "            hbox.layout = widgets.Layout(justify_content=\"space-between\", width=\"100%\")\n",
        "            display(hbox)\n",
        "\n",
        "            # --- NEW: SMART SAVE LOGIC (10 Minute Limit) ---\n",
        "            current_time = time.time()\n",
        "            time_diff = current_time - last_iot_save_time\n",
        "\n",
        "            # 600 seconds = 10 minutes\n",
        "            if time_diff >= 600:\n",
        "                # SAVE TO FIREBASE\n",
        "                if db:\n",
        "                    db.collection('iot_history').add({\n",
        "                        \"soil\": l_soil,\n",
        "                        \"humidity\": l_hum,\n",
        "                        \"temperature\": l_temp,\n",
        "                        \"timestamp\": datetime.now(timezone.utc)\n",
        "                    })\n",
        "\n",
        "                # Update the timer\n",
        "                last_iot_save_time = current_time\n",
        "                print(f\"\\n‚úÖ Data saved to Firestore (Backup successful).\")\n",
        "                print(f\"   Next save allowed in 10 minutes.\")\n",
        "\n",
        "                award_xp(2) # Award XP for the successful save\n",
        "            else:\n",
        "                # SKIP SAVING\n",
        "                mins_left = (600 - time_diff) / 60\n",
        "                print(f\"\\n‚è≥ cloud backup skipped (Throttled).\")\n",
        "                print(f\"   Wait {mins_left:.1f} more minutes to save again.\")\n",
        "            # -----------------------------------------------\n",
        "\n",
        "        except NameError:\n",
        "            print(\"‚Ñπ 'fetch_history' or 'db' is not defined.\")\n",
        "        except Exception as e:\n",
        "            print(\"‚ùå Error fetching/saving data:\", e)\n",
        "\n",
        "b_btn.on_click(fetch_sensor_data)\n",
        "\n",
        "screenB = create_card(\n",
        "    \"IoT Data Logs\",\n",
        "    \"Real-time sensor feeds.\",\n",
        "    [\n",
        "        b_limit,\n",
        "        widgets.HTML(\"<div style='height:16px;'></div>\"),\n",
        "        b_btn,\n",
        "        b_out,\n",
        "    ]\n",
        ")\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# SCREEN C ‚Äî DASHBOARD (Unchanged)\n",
        "# ---------------------------------------------------------------------\n",
        "dash_out = widgets.Output()\n",
        "\n",
        "dash_limit = widgets.IntSlider(\n",
        "    value=30, min=10, max=200, step=10,\n",
        "    description=\"Range:\",\n",
        "    style={'description_width': '60px'},\n",
        "    layout=widgets.Layout(width='80%')\n",
        ")\n",
        "\n",
        "dash_btn = widgets.Button(\n",
        "    description=\"Update Dashboard\",\n",
        "    layout=widgets.Layout(width='60%', height='48px')\n",
        ")\n",
        "dash_btn.add_class(\"btn-warning\")\n",
        "\n",
        "def get_status_color(feed, val):\n",
        "    status = \"OK\"\n",
        "    if feed == \"soil\":\n",
        "        if val < 30: status = \"Critical\"\n",
        "        elif val < 45: status = \"Warning\"\n",
        "    elif feed == \"humidity\":\n",
        "        if val < 30: status = \"Warning\"\n",
        "    elif feed == \"temperature\":\n",
        "        if val < 10 or val > 35: status = \"Warning\"\n",
        "\n",
        "    if status == \"Critical\": return \"#ef4444\", \"Critical\"\n",
        "    if status == \"Warning\": return \"#f59e0b\", \"Warning\"\n",
        "    return \"#10b981\", \"OK\"\n",
        "\n",
        "def build_dashboard(_):\n",
        "    with dash_out:\n",
        "        clear_output()\n",
        "        try:\n",
        "            df_soil = fetch_history(\"soil\", dash_limit.value)\n",
        "            df_hum = fetch_history(\"humidity\", dash_limit.value)\n",
        "            df_temp = fetch_history(\"temperature\", dash_limit.value)\n",
        "        except Exception as e:\n",
        "            print(\"Error fetching data:\", e)\n",
        "            return\n",
        "\n",
        "        val_s = df_soil[\"value\"].iloc[-1] if not df_soil.empty else 0\n",
        "        val_h = df_hum[\"value\"].iloc[-1] if not df_hum.empty else 0\n",
        "        val_t = df_temp[\"value\"].iloc[-1] if not df_temp.empty else 0\n",
        "\n",
        "        col_s, stat_s = get_status_color(\"soil\", val_s)\n",
        "        col_h, stat_h = get_status_color(\"humidity\", val_h)\n",
        "        col_t, stat_t = get_status_color(\"temperature\", val_t)\n",
        "\n",
        "        display(widgets.HTML(f\"\"\"\n",
        "        <div style=\"display:flex; gap:10px; margin-bottom:20px; flex-wrap:wrap;\">\n",
        "            <div style=\"background:{col_s}; color:white; padding:8px 16px; border-radius:20px; font-weight:600; font-size:13px;\">Soil: {stat_s}</div>\n",
        "            <div style=\"background:{col_h}; color:white; padding:8px 16px; border-radius:20px; font-weight:600; font-size:13px;\">Humidity: {stat_h}</div>\n",
        "            <div style=\"background:{col_t}; color:white; padding:8px 16px; border-radius:20px; font-weight:600; font-size:13px;\">Temp: {stat_t}</div>\n",
        "        </div>\n",
        "        \"\"\"))\n",
        "\n",
        "        issues = []\n",
        "        if stat_s in [\"Critical\", \"Warning\"]: issues.append(\"low soil moisture\")\n",
        "        if stat_h in [\"Critical\", \"Warning\"]: issues.append(\"low humidity\")\n",
        "        if stat_t in [\"Critical\", \"Warning\"]: issues.append(\"extreme temperature\")\n",
        "\n",
        "        if issues:\n",
        "            display(widgets.HTML(\"<div style='color:#f59e0b; font-weight:600;'>üí° Generating AI Insight for issues...</div>\"))\n",
        "            query = f\"impact of {', '.join(issues)} on plant health\"\n",
        "            try:\n",
        "                insight = get_rag_response(query) # Using wrapper\n",
        "                display(widgets.HTML(f\"\"\"\n",
        "                    <div style=\"background:#fffbeb; border-left:4px solid #f59e0b; padding:16px; border-radius:8px; margin-bottom:20px; color:#92400e;\">\n",
        "                        <b>AI Diagnosis:</b><br>{insight}\n",
        "                    </div>\n",
        "                \"\"\"))\n",
        "            except: pass\n",
        "\n",
        "        # Plotting requires matplotlib (implied from context)\n",
        "        import matplotlib.pyplot as plt\n",
        "        plt.style.use('default')\n",
        "        plt.figure(figsize=(10, 4))\n",
        "        plt.plot(df_soil[\"created_at\"], df_soil[\"value\"], marker=\"o\", label=\"Soil Moisture\", color=\"#8b5cf6\", linewidth=2)\n",
        "        plt.plot(df_hum[\"created_at\"], df_hum[\"value\"], marker=\"s\", label=\"Humidity\", color=\"#3b82f6\", linewidth=2)\n",
        "        plt.plot(df_temp[\"created_at\"], df_temp[\"value\"], marker=\"^\", label=\"Temperature\", color=\"#ef4444\", linewidth=2)\n",
        "\n",
        "        plt.title(\"Combined Environment Monitoring\", fontsize=12, fontweight='bold', color='#1e293b')\n",
        "        plt.xlabel(\"Time\", color='#64748b')\n",
        "        plt.ylabel(\"Value\", color='#64748b')\n",
        "        plt.grid(True, axis=\"y\", linestyle=\"--\", alpha=0.3)\n",
        "        plt.legend()\n",
        "        plt.xticks(rotation=30)\n",
        "        plt.gca().spines['top'].set_visible(False)\n",
        "        plt.gca().spines['right'].set_visible(False)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "        award_xp(2) # Award XP after the dashboard is built and displayed\n",
        "\n",
        "dash_btn.on_click(build_dashboard)\n",
        "\n",
        "screenC = create_card(\"Live Dashboard\", \"Real-time visualization.\", [dash_limit, widgets.HTML(\"<div style='height:16px;'></div>\"), dash_btn, dash_out])\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# SCREEN D ‚Äî SEARCH (RESTORED DETAILS)\n",
        "# ---------------------------------------------------------------------\n",
        "c_out = widgets.Output()\n",
        "index_box = widgets.Text(value=\"inverted_index\", description=\"Index:\", style={'description_width': '60px'}, layout=widgets.Layout(width=\"70%\"))\n",
        "query_box = widgets.Text(value=\"about\", description=\"Query:\", style={'description_width': '60px'}, layout=widgets.Layout(width=\"70%\"))\n",
        "search_btn = widgets.Button(description=\"Search DB\", layout=widgets.Layout(width='50%', height='48px', margin='10px 0 0 70px'))\n",
        "search_btn.add_class(\"btn-primary\")\n",
        "\n",
        "def search_inverted_index(index_name: str, term: str):\n",
        "    index_name = index_name.strip()\n",
        "    term = term.strip().lower()\n",
        "    if not index_name or not term:\n",
        "        return None, \"Enter both Index and Search.\"\n",
        "\n",
        "    if not db: return None, \"DB not connected\"\n",
        "\n",
        "    doc = db.collection(index_name).document(term).get()\n",
        "    if doc.exists:\n",
        "        data = doc.to_dict() or {}\n",
        "        return {\n",
        "            \"term\": term,\n",
        "            \"df\": data.get(\"df\"),\n",
        "            \"doc_ids\": data.get(\"doc_ids\", [])\n",
        "        }, None\n",
        "\n",
        "    qs = list(db.collection(index_name).where(\"term\", \"==\", term).limit(1).stream())\n",
        "    if qs:\n",
        "        data = qs[0].to_dict() or {}\n",
        "        return {\n",
        "            \"term\": term,\n",
        "            \"df\": data.get(\"df\"),\n",
        "            \"doc_ids\": data.get(\"doc_ids\", [])\n",
        "        }, None\n",
        "\n",
        "    return None, f\"No results for '{term}' in '{index_name}'.\"\n",
        "\n",
        "def on_search_click(_):\n",
        "    with c_out:\n",
        "        clear_output()\n",
        "        try:\n",
        "            result, err = search_inverted_index(index_box.value, query_box.value)\n",
        "        except NameError:\n",
        "            print(\"‚ÑπÔ∏è Firestore client 'db' is not defined.\")\n",
        "            return\n",
        "        if err:\n",
        "            print(err)\n",
        "            return\n",
        "\n",
        "        if result:\n",
        "            award_xp(1) # Award XP if search yields results\n",
        "            # FIXED: Explicitly showing Frequency (DF) and list of IDs\n",
        "            html = \"<ul style='padding-left:18px; color:#475569; max-height:100px; overflow-y:auto;'>\"\n",
        "            for did in result.get(\"doc_ids\", []):\n",
        "                html += f\"<li>{did}</li>\"\n",
        "            html += \"</ul>\"\n",
        "\n",
        "            display(widgets.HTML(f\"\"\"\n",
        "                <div style=\"background:#f8fafc; padding:20px; border-radius:12px; border:1px solid #e2e8f0;\">\n",
        "                    <p style=\"margin:5px 0; font-size:16px;\"><b>Term:</b> <span style=\"color:#4f46e5; font-weight:bold;\">{result['term']}</span></p>\n",
        "                    <p style=\"margin:5px 0; font-size:16px;\"><b>Mentioned:</b> <span style=\"font-weight:bold; color:#0f172a;\">{result.get('df', 0)} times</span> (Document Frequency)</p>\n",
        "                    <div style=\"margin-top:15px; font-weight:600; color:#64748b; border-bottom:1px solid #e2e8f0; padding-bottom:5px;\">Found in Documents:</div>\n",
        "                    {html}\n",
        "                </div>\n",
        "            \"\"\"))\n",
        "\n",
        "search_btn.on_click(on_search_click)\n",
        "screenD = create_card(\"Knowledge Search\", \"Query the Firestore index.\", [index_box, query_box, search_btn, c_out])\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# SCREEN E ‚Äî CHAT (RAG)\n",
        "# ---------------------------------------------------------------------\n",
        "chat_out = widgets.Output()\n",
        "chat_out.add_class(\"chat-window\")\n",
        "chat_box = widgets.Textarea(\n",
        "    placeholder=\"Ask about plant diseases... (Press Enter)\",\n",
        "    layout=widgets.Layout(width=\"100%\", height=\"80px\")\n",
        ")\n",
        "send_btn = widgets.Button(description=\"Send\", layout=widgets.Layout(width=\"120px\", height=\"40px\"))\n",
        "send_btn.add_class(\"btn-primary\")\n",
        "clear_btn = widgets.Button(description=\"Clear\", layout=widgets.Layout(width=\"120px\", height=\"40px\"))\n",
        "status_line = widgets.HTML(\"\")\n",
        "\n",
        "def render_message(role, text):\n",
        "    align = \"flex-end\" if role == \"user\" else \"flex-start\"\n",
        "    bg = \"#4f46e5\" if role == \"user\" else \"#f8fafc\"\n",
        "    col = \"white\" if role == \"user\" else \"#1e293b\"\n",
        "    border = \"none\" if role == \"user\" else \"1px solid #e2e8f0\"\n",
        "\n",
        "    bubble = f\"\"\"<div style=\"display:flex; justify-content:{align}; margin:15px 0;\">\n",
        "          <div style=\"max-width:75%; background:{bg}; color:{col}; padding:12px 16px; border-radius:18px 18px 4px 18px; border:{border}; font-size:14px;\">{text}</div></div>\"\"\"\n",
        "    display(widgets.HTML(bubble))\n",
        "\n",
        "def handle_send(_=None):\n",
        "    q = chat_box.value.strip()\n",
        "    if not q: return\n",
        "    chat_box.value = \"\"\n",
        "\n",
        "    # 1. Render User Message\n",
        "    with chat_out: render_message(\"user\", q)\n",
        "\n",
        "    try:\n",
        "        status_line.value = \"<span style='color:#4f46e5; font-weight:600;'>üß† Thinking...</span>\"\n",
        "\n",
        "        # 2. CALL CELL 14 LOGIC\n",
        "        final = get_rag_response(q)\n",
        "\n",
        "        status_line.value = \"\"\n",
        "\n",
        "        # 3. Render AI Message\n",
        "        with chat_out: render_message(\"ai\", final)\n",
        "        award_xp(1) # Award XP after AI message is rendered in RAG chat\n",
        "\n",
        "    except Exception as e:\n",
        "        status_line.value = \"\"\n",
        "        with chat_out: render_message(\"ai\", f\"Error: {e}\")\n",
        "\n",
        "def on_rag_enter(change):\n",
        "    if change[\"new\"].endswith(\"\\n\"):\n",
        "        chat_box.value = chat_box.value.strip()\n",
        "        handle_send()\n",
        "\n",
        "chat_box.observe(on_rag_enter, names=\"value\")\n",
        "send_btn.on_click(handle_send)\n",
        "clear_btn.on_click(lambda _: chat_out.clear_output())\n",
        "\n",
        "screenE = create_card(\n",
        "    \"AI Assistant (RAG)\",\n",
        "    \"Chat with your data.\",\n",
        "    [chat_out, widgets.HTML(\"<div style='height:16px;'></div>\"), chat_box, widgets.HBox([send_btn, clear_btn]), status_line]\n",
        ")\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# SCREEN F ‚Äî GEMINI CHAT\n",
        "# ---------------------------------------------------------------------\n",
        "gem_out = widgets.Output()\n",
        "gem_out.add_class(\"chat-window\")\n",
        "gem_input = widgets.Textarea(placeholder=\"Ask Gemini... (Press Enter)\", layout=widgets.Layout(width=\"100%\", height=\"80px\"))\n",
        "gem_send = widgets.Button(description=\"Send\", layout=widgets.Layout(width=\"120px\", height=\"40px\"))\n",
        "gem_send.add_class(\"btn-primary\")\n",
        "gem_clear = widgets.Button(description=\"Clear\", layout=widgets.Layout(width=\"120px\", height=\"40px\"))\n",
        "gem_stat = widgets.HTML(\"\")\n",
        "\n",
        "def gem_logic(_=None):\n",
        "    q = gem_input.value.strip()\n",
        "    if not q: return\n",
        "    gem_input.value = \"\"\n",
        "    with gem_out: render_message(\"user\", q)\n",
        "    try:\n",
        "        gem_stat.value = \"<b style='color:#4f46e5'>Thinking...</b>\"\n",
        "        resp = chat_session.send_message(q)\n",
        "        gem_stat.value = \"\"\n",
        "        with gem_out: render_message(\"ai\", resp.text)\n",
        "        award_xp(1) # Award XP after AI message is rendered in Gemini chat\n",
        "    except Exception as e:\n",
        "        gem_stat.value = \"\"\n",
        "        with gem_out: render_message(\"ai\", f\"Error: {e}\")\n",
        "\n",
        "def on_gem_enter(change):\n",
        "    if change[\"new\"].endswith(\"\\n\"):\n",
        "        gem_input.value = gem_input.value.strip()\n",
        "        gem_logic()\n",
        "\n",
        "gem_input.observe(on_gem_enter, names=\"value\")\n",
        "gem_send.on_click(gem_logic)\n",
        "gem_clear.on_click(lambda _: gem_out.clear_output())\n",
        "\n",
        "screenF = create_card(\"Gemini Direct\", \"Clean workspace.\", [gem_out, widgets.HTML(\"<div style='height:16px;'></div>\"), gem_input, widgets.HBox([gem_send, gem_clear]), gem_stat])\n",
        "\n",
        "# ---------------------------------------------------------------------\n",
        "# FINAL ASSEMBLY\n",
        "# ---------------------------------------------------------------------\n",
        "tabs = widgets.Tab(children=[screenA, screenB, screenC, screenD, screenE, screenF, screenG])\n",
        "tabs.set_title(0, \"Diagnosis\")\n",
        "tabs.set_title(1, \"IoT Data\")\n",
        "tabs.set_title(2, \"Dashboard\")\n",
        "tabs.set_title(3, \"Search\")\n",
        "tabs.set_title(4, \"RAG Chat\")\n",
        "tabs.set_title(5, \"Gemini\")\n",
        "tabs.set_title(6, \"Leaderboard\") # New Leaderboard tab title\n",
        "\n",
        "header = widgets.HTML(\n",
        "    \"\"\"<div style='display:flex; align-items:center; gap:12px; margin-bottom:20px; border-bottom:1px solid #e2e8f0; padding-bottom:20px;'>\n",
        "        <div style='width:40px; height:40px; background:#4f46e5; border-radius:10px; display:flex; align-items:center; justify-content:center; color:white; font-size:20px;'>üå±</div>\n",
        "        <div><h1 style='margin:0; font-size:24px; color:#1e293b;'>PlantCare AI</h1></div>\n",
        "    </div>\"\"\"\n",
        ")\n",
        "\n",
        "app = widgets.VBox([header, tabs])\n",
        "app.add_class(\"app-shell\")\n",
        "display(app)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}